<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Facial Recognition Laws in China #ProjectPanoptic | Internet Freedom Foundation</title>
<meta name=keywords content="Project Panoptic,facial recognition">
<meta name=description content="In the third part of our series on FRT regulation around the world, we will take a look at what are the existing laws regulating FRT in China, the reality of FRT development  & use by it and how it affects India.">
<meta name=author content="Anushka Jain">
<link rel=canonical href=https://archive.internetfreedom.in/post/facial-recognition-laws-in-china/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<link rel=preload href=/iff-logo-600x250.png as=image>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://archive.internetfreedom.in/iff-icon-125.png>
<link rel=icon type=image/png sizes=16x16 href=https://archive.internetfreedom.in/iff-icon-125.png>
<link rel=icon type=image/png sizes=32x32 href=https://archive.internetfreedom.in/iff-icon-125.png>
<link rel=apple-touch-icon href=https://archive.internetfreedom.in/iff-icon-125.png>
<link rel=mask-icon href=https://archive.internetfreedom.in/iff-icon-125.png>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="Facial Recognition Laws in China #ProjectPanoptic">
<meta property="og:description" content="In the third part of our series on FRT regulation around the world, we will take a look at what are the existing laws regulating FRT in China, the reality of FRT development  & use by it and how it affects India.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://archive.internetfreedom.in/post/facial-recognition-laws-in-china/"><meta property="og:image" content="https://archive.internetfreedom.in/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post">
<meta property="article:published_time" content="2021-06-03T14:38:04+00:00">
<meta property="article:modified_time" content="2021-06-03T14:38:04+00:00"><meta property="og:site_name" content="Internet Freedom Foundation">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://archive.internetfreedom.in/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E">
<meta name=twitter:title content="Facial Recognition Laws in China #ProjectPanoptic">
<meta name=twitter:description content="In the third part of our series on FRT regulation around the world, we will take a look at what are the existing laws regulating FRT in China, the reality of FRT development  & use by it and how it affects India.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://archive.internetfreedom.in/post/"},{"@type":"ListItem","position":3,"name":"Facial Recognition Laws in China #ProjectPanoptic","item":"https://archive.internetfreedom.in/post/facial-recognition-laws-in-china/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Facial Recognition Laws in China #ProjectPanoptic","name":"Facial Recognition Laws in China #ProjectPanoptic","description":"In the third part of our series on FRT regulation around the world, we will take a look at what are the existing laws regulating FRT in China, the reality of FRT development  \u0026amp; use by it and how it affects India.","keywords":["Project Panoptic","facial recognition"],"articleBody":"            tl;dr In the last part of this series, we will take a look at the existing laws in China which relate to facial recognition technology (FRT) and how they fail to adequately protect the human rights of Chinese citizens. We will also look at how FRT developed in China is being exported throughout the world, specifically India, and what this means for Indian citizens.\nExisting laws \u0026 regulations in China related to facial recognition The Cybersecurity Law of the People’s Republic of China, which came into force on June 1, 2017, was enacted to ensure cybersecurity and to safeguard cyberspace sovereignty \u0026 national security. The law states that, “Network operators carrying out business and service activities must follow laws and administrative regulations…”. These legal obligations lay down certain requirements for the collection, use and protection of personally identifiable information (PII), which includes ‘biometric data’. However, the law is focused more on cybersecurity, in the context of national security, than on protection of ‘biometric data’, which finds a mention only in the definition section (Article 76).\nArticle 76 Clause (5) of the law defines ‘personal information’(PI) as “all kinds of information, recorded electronically or through other means, that taken alone or together with other information, is sufficient to identify a natural person’s identity, including but not limited to natural persons’ full names, birth dates, national identification numbers, personal biometric information, addresses, telephone numbers, and so forth.” (emphasis added)\nThe regulation which relates more specifically to data protection is China’s Personal Information Security Specification, which came into force on October 1, 2020. As per the introduction to the specification, it aims to “targets security challenges to PI, and regulates related behaviors by PI controllers during information processing such as collection, retention, use, sharing, transfer, and public disclosure” while also “protecting individuals‘ lawful rights and interests and society’s public interests to the greatest degree” by laying down guidelines for data-handling and protection.\nUnder the specification, ‘personal information’ includes “names, dates of birth, identity card numbers, biometric information, addresses, telecommunication contact methods, communication records and contents, account passwords, property information, credit information, location data, accommodation information, health and physiological information, transaction data, etc.” However, the specification is non-binding and does not impose any penalties. China is also reportedly working on a new data privacy law with a stronger focus on biometrics, however, enforcement of these laws remains an issue.\nAdditionally, on April 23, 2021, China published a draft standard on Security Requirements of Facial Recognition Data which lays down requirements for the collection, processing, sharing and transfer of facial recognition related data and is open for public consultation. This standard, however, is also non-mandatory. The requirements laid down in the standard are that:\n use of this data should only be for identification purposes and no predictions should be made on its basis, FRT should be used only when no alternative technology is available to fulfil the purpose of security or convenience, Individuals under 14 should not be identified on the basis of FRT, FRT data should not be stored without obtaining consent and FRT data generated or collected in China should be stored locally.  Is something better than nothing?: Reality of FRT development and use in China The laws and regulations discussed above which are in force do not explicitly regulate FRT and those that do are either non-binding or in the draft stage. Thus, while China claims to regulate FRT and respect citizens’ rights, the reality of surveillance in China, especially FRT surveillance, is in stark contrast.\nAccording to a 2018 BBC news report, “(a)n estimated 170 million CCTV cameras are already in place and some 400 million new ones are expected (to) be installed in the next three years.” According to a study of 6100 Chinese citizens conducted by the Nandu Personal Information Protection Research Center in 2019, “83% of respondents indicated that they would like to have more control over their data and 75% would prefer the option to have traditional methods of identification over FRT”.\nMore troublesome are the reports which provide insight into how this technology is being developed and used in China against ethnic minorities such as the Uighurs, most of whom are Muslim. A software engineer told the BBC, “The Chinese government use(s) Uighurs as test subjects for various experiments just like rats are used in laboratories.” There are multiple reports of Chinese companies marketing or obtaining patents for FRT which specifically picks out the Uighur minority:\n Patent filed in July 2018 by Huawei and the China Academy of Sciences describes a face recognition product that is capable of identifying people on the basis of their ethnicity. Huawei and Megvii, another Chinese technology company, started collaborating in 2018 to “test an artificial-intelligence camera system that could scan faces in a crowd and estimate each person’s age, sex and ethnicity” and could set off a ‘Uighur alarm’ to the Chinese government when the software identified someone from the persecuted minority group. Similarly, Alibaba’s FRT was also reported to specifically pick out the Uighur minority. Hikvision has also been reported to have developed and deployed FRT capable of minority analytics in China.  China has justified its surveillance actions on the basis that they have been trying to weed out extremist factions from the majorly Muslim Uighur community to protect public security. According to Alim, a Uighur man in his 20s, who was detained after a facial recognition software identified him as Uighur, “(c)ontrolling the Uighurs has also become a test case for marketing Chinese technological prowess around the world. A hundred government agencies and companies from two dozen countries, including the US, France, Israel and the Philippines, now participate in the highly influential annual China-Eurasia Security Expo in Urumqi, the capital of the Uighur region. The ethos at the expo, and in the Chinese techno-security industry as a whole, is that Muslim populations need to be managed and made productive.” A reported 5 lakh facial scans were run by the law enforcement in the central Chinese city of Sanmenxia that, over the course of a month in 2019, screened whether residents were Uighurs.\nHere, it is also important to look at the concept of ‘Potemkin AI’, coined by Jathan Sadowski, in which the author theorises that many instances of “artificial intelligence” are just artificial displays of its power and potential wherein, even though the AI purports to be powered by sophisticated software, it actually relies on humans acting as robots. According to him, “(w)hether it’s content moderation for social media or image recognition for police surveillance, claims abound about the effectiveness of AI-powered analytics, when, in reality, the cognitive labor comes from an office building full of (low-waged) workers.” “While facial recognition technology uses aspects like skin tone and face shapes to sort images in photos or videos, it must be told by humans to categorize people based on social definitions of race or ethnicity. Chinese police, with the help of the start-ups, have done that.” The point to be noted here is that “it matters less if the system actually works that way than if people believe it does and act accordingly”. Thus, FRT surveillance in China can be said to also be more about self-regulation by the Uighurs to stamp out their religious identity, than about accurately identifying any links to extremism.\nThis has also led to China’s emergence as a leader in “terror capitalism”, a fairly new term coined by Darren Byler, under which exploitation of subjugated populations is justified by defining them as potential terrorists or security threats. According to Byler, terror capitalism generates profits by the following process:\n Profitable government contracts are given to private companies in order to build and deploy policing technologies that surveil and manage target groups. Then, using the vast amounts of biometric and social media data extracted from those groups, the private companies improve their technologies and sell retail versions of them to other states and institutions, such as schools. Finally, all this turns the target groups into a ready source of cheap labor – either through direct coercion or indirectly through stigma. (Source: https://www.theguardian.com/world/2020/jul/24/surveillance-tech-facial-recognition-terror-capitalism)  Note: Darren Byler is a postdoctoral researcher in the ChinaMade project at the University of Colorado, Boulder. He received his PhD from the Department of Anthropology at the University of Washington in 2018. His research focuses on Uyghur dispossession, infrastructural power and “terror capitalism” in the city of Ürümchi, the capital of Chinese Central Asia (Xinjiang).\nHow does this affect India? China is the biggest supplier of surveillance technologies worldwide, with technology linked to Chinese companies, particularly Huawei, Hikvision, Dahua, and ZTE, supplying AI surveillance technology in sixty-three countries, of which Huawei is responsible for 50 countries. According to Kai-Fu Lee, who is an investor in the chinese company Megvii and a supporter of the expansion of Chinese AI, “China has an advantage in developing A.I. because its leaders are less fussed by “legal intricacies” or “moral consensus””.\nAs stated above, these systems are developed by the Police, while working with these companies, wherein the Police supplies the database of criminals. Efforts to create such databases in India have accelerated in the past couple of years (CCTNS, NatGrid). The Delhi Government, in 2019, hired HikVision to set up 1,50,000 CCTVs in the city. Inaccurate technology systems which have been developed by and for committing violations of privacy and human rights, should not be implemented in India.\nFurther, the cost of implementing these systems is enormous. According to IFF’s Project Panoptic, almost 1,248.82 Cr INR has been spent on FRT systems in the country to date. With the country being in the throes of a once in a century pandemic, which has devastated millions, resources should not be diverted towards building a surveillance regime that will further traumatise Indians but towards improving the quality of life in the country, especially the crumbling public health infrastructure. Finally, remember that all this is being done in the absence of a data protection law in India.\nImportant documents  Facial Recognition Laws in Europe dated May 13, 2021 (link) Facial Recognition Laws in the United States dated May 3, 2021 (link)        ","wordCount":"1682","inLanguage":"en","datePublished":"2021-06-03T14:38:04Z","dateModified":"2021-06-03T14:38:04Z","author":{"@type":"Person","name":"Anushka Jain"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://archive.internetfreedom.in/post/facial-recognition-laws-in-china/"},"publisher":{"@type":"Organization","name":"Internet Freedom Foundation","logo":{"@type":"ImageObject","url":"https://archive.internetfreedom.in/iff-icon-125.png"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://archive.internetfreedom.in accesskey=h title="IFF (Alt + H)">
<img src=https://archive.internetfreedom.in/iff-logo-600x250.png alt=logo aria-label=logo height=40>IFF</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://archive.internetfreedom.in/archives title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://archive.internetfreedom.in/about/ title=About>
<span>About</span>
</a>
</li>
<li>
<a href=https://archive.internetfreedom.in/categories/ title=Categories>
<span>Categories</span>
</a>
</li>
<li>
<a href=https://archive.internetfreedom.in/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Facial Recognition Laws in China #ProjectPanoptic
</h1>
<div class=post-meta><span title="2021-06-03 14:38:04 +0000 UTC">June 3, 2021</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Anushka Jain&nbsp;|&nbsp;<a href=https://github.com/InternetFreedomFoundation/archive/tree/main/content/post/facial-recognition-laws-in-china.md rel="noopener noreferrer" target=_blank>Suggest Changes</a>
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#tldr aria-label=tl;dr>tl;dr</a></li>
<li>
<a href=#existing-laws--regulations-in-china-related-to-facial-recognition aria-label="Existing laws &amp;amp; regulations in China related to facial recognition">Existing laws & regulations in China related to facial recognition</a></li>
<li>
<a href=#is-something-better-than-nothing-reality-of-frt-development-and-use-in-china aria-label="Is something better than nothing?: Reality of FRT development and use in China">Is something better than nothing?: Reality of FRT development and use in China</a></li>
<li>
<a href=#how-does-this-affect-india aria-label="How does this affect India?">How does this affect India?</a></li>
<li>
<a href=#important-documents aria-label="Important documents">Important documents</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><figure class="kg-gallery-card kg-width-wide">
<div class=kg-gallery-container>
<div class=kg-gallery-row>
<div class=kg-gallery-image>
<img src=https://internetfreedom.in/content/images/2021/06/Copy-of-A-2018-patent-by-Huawei-and-China-Academy-of-Sciences-describes-a-face-recognition-product-capable-of-identifying-people-on-the-basis-of-their-ethnicity..png width=100% height=auto>
</div>
</div>
</div>
</figure>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<h3 id=tldr>tl;dr<a hidden class=anchor aria-hidden=true href=#tldr>#</a></h3>
<p>In the last part of this <a href=https://internetfreedom.in/facial-recognition-laws-in-europe-projectpanoptic/>series</a>, we will take a look at the existing laws in China which relate to facial recognition technology (FRT) and how they fail to adequately protect the human rights of Chinese citizens. We will also look at how FRT developed in China is being exported throughout the world, specifically India, and what this means for Indian citizens.</p>
<h3 id=existing-laws--regulations-in-china-related-to-facial-recognition>Existing laws & regulations in China related to facial recognition<a hidden class=anchor aria-hidden=true href=#existing-laws--regulations-in-china-related-to-facial-recognition>#</a></h3>
<p>The <a href=https://www.newamerica.org/cybersecurity-initiative/digichina/blog/translation-cybersecurity-law-peoples-republic-china/>Cybersecurity Law of the People’s Republic of China</a>, which came into force on June 1, 2017, was enacted to ensure cybersecurity and to safeguard cyberspace sovereignty & national security. The law states that, “Network operators carrying out business and service activities must follow laws and administrative regulations…”. These legal obligations lay down certain requirements for the collection, use and protection of personally identifiable information (PII), which includes ‘biometric data’. However, the law is focused more on cybersecurity, in the context of national security, than on protection of ‘biometric data’, which finds a mention only in the definition section (Article 76).</p>
<p>Article 76 Clause (5) of the law defines ‘personal information’(PI) as “all kinds of information, recorded electronically or through other means, that taken alone or together with other information, is sufficient to identify a natural person’s identity, including but not limited to natural persons’ full names, birth dates, national identification numbers, <strong>personal biometric information</strong>, addresses, telephone numbers, and so forth.” (emphasis added)</p>
<p>The regulation which relates more specifically to data protection is <a href=https://web.archive.org/web/20201124083428/https://www.tc260.org.cn/upload/2020-09-18/1600432872689070371.pdf>China’s Personal Information Security Specification</a>, which came into force on October 1, 2020. As per the introduction to the specification, it aims to “targets security challenges to PI, and regulates related behaviors by PI controllers during information processing such as collection, retention, use, sharing, transfer, and public disclosure” while also “protecting individuals‘ lawful rights and interests and society’s public interests to the greatest degree” by laying down guidelines for data-handling and protection.</p>
<p>Under the specification, ‘personal information’ includes “names, dates of birth, identity card numbers, biometric information, addresses, telecommunication contact methods, communication records and contents, account passwords, property information, credit information, location data, accommodation information, health and physiological information, transaction data, etc.” However, the specification is non-binding and does not impose any penalties. China is also reportedly working on a new data privacy law with a stronger focus on biometrics, however, <a href="https://www.scmp.com/news/china/politics/article/3008844/china-working-data-privacy-law-enforcement-stumbling-block?_ga=2.248015815.1981978166.1583522672-1093883729.1583178792">enforcement of these laws remains an issue</a>.</p>
<p>Additionally, on April 23, 2021, China published a <a href=https://www.natlawreview.com/article/china-publishes-draft-security-standard-facial-recognition>draft standard on Security Requirements of Facial Recognition Data</a> which lays down requirements for the collection, processing, sharing and transfer of facial recognition related data and is open for public consultation. This standard, however, is also non-mandatory. The requirements laid down in the standard are that:</p>
<ul>
<li>use of this data should only be for identification purposes and no predictions should be made on its basis,</li>
<li>FRT should be used only when no alternative technology is available to fulfil the purpose of security or convenience,</li>
<li>Individuals under 14 should not be identified on the basis of FRT,</li>
<li>FRT data should not be stored without obtaining consent and</li>
<li>FRT data generated or collected in China should be stored locally.</li>
</ul>
<h3 id=is-something-better-than-nothing-reality-of-frt-development-and-use-in-china>Is something better than nothing?: Reality of FRT development and use in China<a hidden class=anchor aria-hidden=true href=#is-something-better-than-nothing-reality-of-frt-development-and-use-in-china>#</a></h3>
<p>The laws and regulations discussed above which are in force do not explicitly regulate FRT and those that do are either non-binding or in the draft stage. Thus, while China claims to regulate FRT and respect citizens’ rights, the reality of surveillance in China, especially FRT surveillance, is in stark contrast.</p>
<p>According to a <a href=https://www.bbc.com/news/world-asia-china-43751276>2018 BBC news report</a>, “(a)n estimated 170 million CCTV cameras are already in place and some 400 million new ones are expected (to) be installed in the next three years.” According to a study of 6100 Chinese citizens conducted by the Nandu Personal Information Protection Research Center in 2019, “<a href=https://journals.sagepub.com/doi/full/10.1177/09636625211001555>83% of respondents indicated that they would like to have more control over their data and 75% would prefer the option to have traditional methods of identification over FRT</a>”.</p>
<p>More troublesome are the reports which provide insight into how this technology is being developed and used in China against ethnic minorities such as the Uighurs, most of whom are Muslim. A software engineer told the <a href=https://www.bbc.com/news/technology-57101248>BBC</a>, “The Chinese government use(s) Uighurs as test subjects for various experiments just like rats are used in laboratories.” There are multiple reports of Chinese companies marketing or obtaining patents for FRT which specifically picks out the Uighur minority:</p>
<ol>
<li>Patent filed in July 2018 by <a href=https://ipvm.com/reports/patents-uyghur>Huawei</a> and the China Academy of Sciences describes a face recognition product that is capable of identifying people on the basis of their ethnicity.</li>
<li><a href=https://ipvm.com/reports/huawei-megvii-uygur>Huawei and Megvii</a>, another Chinese technology company, started collaborating in 2018 to “test an artificial-intelligence camera system that could scan faces in a crowd and estimate each person’s age, sex and ethnicity” and could set off a &lsquo;Uighur alarm&rsquo; to the Chinese government when the software identified someone from the persecuted minority group.</li>
<li>Similarly, <a href=https://ipvm.com/reports/alibaba-uyghur>Alibaba&rsquo;s</a> FRT was also reported to specifically pick out the Uighur minority.</li>
<li><a href=https://ipvm.com/reports/hikvision-minority>Hikvision</a> has also been reported to have developed and deployed FRT capable of minority analytics in China.</li>
</ol>
<p>China has justified its surveillance actions on the basis that they have been trying to weed out extremist factions from the majorly Muslim Uighur community to protect public security. <a href=https://www.theguardian.com/news/2019/apr/11/china-hi-tech-war-on-muslim-minority-xinjiang-uighurs-surveillance-face-recognition>According to Alim</a>, a Uighur man in his 20s, who was detained after a facial recognition software identified him as Uighur, “(c)ontrolling the Uighurs has also become a test case for marketing Chinese technological prowess around the world. A hundred government agencies and companies from two dozen countries, including the US, France, Israel and the Philippines, now participate in the highly influential annual China-Eurasia Security Expo in Urumqi, the capital of the Uighur region. The ethos at the expo, and in the Chinese techno-security industry as a whole, is that Muslim populations need to be managed and made productive.” A reported <a href=https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html>5 lakh facial scans</a> were run by the law enforcement in the central Chinese city of Sanmenxia that, over the course of a month in 2019, screened whether residents were Uighurs.</p>
<p>Here, it is also important to look at the concept of ‘<a href=https://reallifemag.com/potemkin-ai/>Potemkin AI</a>’, coined by Jathan Sadowski, in which the author theorises that many instances of “artificial intelligence” are just artificial displays of its power and potential wherein, even though the AI purports to be powered by sophisticated software, it actually relies on humans acting as robots. According to him, “(w)hether it’s content moderation for social media or image recognition for police surveillance, claims abound about the effectiveness of AI-powered analytics, when, in reality, the cognitive labor comes from an office building full of (low-waged) workers.” “<a href=https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html>While facial recognition technology uses aspects like skin tone and face shapes to sort images in photos or videos, it must be told by humans to categorize people based on social definitions of race or ethnicity. Chinese police, with the help of the start-ups, have done that.</a>” The point to be noted here is that “it matters less if the system actually works that way than if people believe it does and act accordingly”. Thus, FRT surveillance in China can be said to also be more about <a href=https://indianexpress.com/article/explained/uighur-muslims-detention-camps-china-leaked-documents-nyt-6125674/>self-regulation by the Uighurs to stamp out their religious identity, than about accurately identifying any links to extremism</a>.</p>
<p>This has also led to China’s emergence as a leader in “<a href=https://www.theguardian.com/world/2020/jul/24/surveillance-tech-facial-recognition-terror-capitalism>terror capitalism</a>”, a fairly new term coined by <a href=https://digital.lib.washington.edu/researchworks/handle/1773/42946>Darren Byler</a>, under which exploitation of subjugated populations is justified by defining them as potential terrorists or security threats. According to Byler, terror capitalism generates profits by the following process:</p>
<ol>
<li>Profitable government contracts are given to private companies in order to build and deploy policing technologies that surveil and manage target groups.</li>
<li>Then, using the vast amounts of biometric and social media data extracted from those groups, the private companies improve their technologies and sell retail versions of them to other states and institutions, such as schools.</li>
<li>Finally, all this turns the target groups into a ready source of cheap labor – either through direct coercion or indirectly through stigma. (Source: <a href=https://www.theguardian.com/world/2020/jul/24/surveillance-tech-facial-recognition-terror-capitalism>https://www.theguardian.com/world/2020/jul/24/surveillance-tech-facial-recognition-terror-capitalism</a>)</li>
</ol>
<p><strong>Note</strong>: <a href=https://anthropology.washington.edu/people/darren-byler>Darren Byler</a> is a postdoctoral researcher in the ChinaMade project at the University of Colorado, Boulder. He received his PhD from the Department of Anthropology at the University of Washington in 2018. His research focuses on Uyghur dispossession, infrastructural power and &ldquo;terror capitalism&rdquo; in the city of Ürümchi, the capital of Chinese Central Asia (Xinjiang).</p>
<h3 id=how-does-this-affect-india>How does this affect India?<a hidden class=anchor aria-hidden=true href=#how-does-this-affect-india>#</a></h3>
<p>China is the biggest supplier of surveillance technologies worldwide, with technology linked to Chinese companies, particularly Huawei, Hikvision, Dahua, and ZTE, supplying AI surveillance technology in <a href=https://carnegieendowment.org/2019/09/17/global-expansion-of-ai-surveillance-pub-79847>sixty-three countries</a>, of which Huawei is responsible for 50 countries. According to Kai-Fu Lee, who is an investor in the chinese company Megvii and a supporter of the expansion of Chinese AI, “<a href=https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html>China has an advantage in developing A.I. because its leaders are less fussed by “legal intricacies” or “moral consensus</a>””.</p>
<p>As stated above, these systems are developed by the Police, while working with these companies, wherein the Police supplies the database of criminals. Efforts to create such databases in India have accelerated in the past couple of years (<a href=https://internetfreedom.in/watch-the-watchmen-part-3/>CCTNS</a>, <a href=https://internetfreedom.in/watch-the-watchmen-part-1-the-national-intelligence-grid/>NatGrid</a>). The Delhi Government, in 2019, hired HikVision to set up <a href="https://economictimes.indiatimes.com/news/politics-and-nation/india-is-planning-a-huge-china-style-facial-recognition-program/articleshow/71213132.cms?from=mdr">1,50,000 CCTVs</a> in the city. Inaccurate technology systems which have been developed by and for committing violations of privacy and human rights, should not be implemented in India.</p>
<p>Further, the cost of implementing these systems is enormous. According to IFF’s <a href=https://panoptic.in/>Project Panoptic</a>, almost 1,248.82 Cr INR has been spent on FRT systems in the country to date. With the country being in the throes of a once in a century pandemic, which has devastated millions, resources should not be diverted towards building a surveillance regime that will further traumatise Indians but towards improving the quality of life in the country, especially the crumbling public health infrastructure. Finally, remember that all this is being done in the absence of a <a href=https://internetfreedom.in/tag/dataprotectiontop10/>data protection law</a> in India.</p>
<h3 id=important-documents>Important documents<a hidden class=anchor aria-hidden=true href=#important-documents>#</a></h3>
<ol>
<li>Facial Recognition Laws in Europe dated May 13, 2021 (<a href=https://internetfreedom.in/facial-recognition-laws-in-europe-projectpanoptic/>link</a>)</li>
<li>Facial Recognition Laws in the United States dated May 3, 2021 (<a href=https://internetfreedom.in/facial-recognition-laws-in-the-united-states-projectpanoptic/>link</a>)</li>
</ol>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
</blockquote>
</blockquote>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://archive.internetfreedom.in/tags/project-panoptic/>Project Panoptic</a></li>
<li><a href=https://archive.internetfreedom.in/tags/facial-recognition/>facial recognition</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://archive.internetfreedom.in/post/dataprotectiontop10-protecting-whistleblowers-digital-security-researchers-and-vulnerability-testers/>
<span class=title>« Prev Page</span>
<br>
<span>#DataProtectionTop10: Protecting whistleblowers, digital security researchers, and vulnerability testers</span>
</a>
<a class=next href=https://archive.internetfreedom.in/post/delhi-governments-gag-order-on-information-on-mucormycosis/>
<span class=title>Next Page »</span>
<br>
<span>Delhi Government’s gag order on information on mucormycosis</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Facial Recognition Laws in China #ProjectPanoptic on twitter" href="https://twitter.com/intent/tweet/?text=Facial%20Recognition%20Laws%20in%20China%20%23ProjectPanoptic&url=https%3a%2f%2farchive.internetfreedom.in%2fpost%2ffacial-recognition-laws-in-china%2f&hashtags=ProjectPanoptic%2cfacialrecognition"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Facial Recognition Laws in China #ProjectPanoptic on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2farchive.internetfreedom.in%2fpost%2ffacial-recognition-laws-in-china%2f&title=Facial%20Recognition%20Laws%20in%20China%20%23ProjectPanoptic&summary=Facial%20Recognition%20Laws%20in%20China%20%23ProjectPanoptic&source=https%3a%2f%2farchive.internetfreedom.in%2fpost%2ffacial-recognition-laws-in-china%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Facial Recognition Laws in China #ProjectPanoptic on reddit" href="https://reddit.com/submit?url=https%3a%2f%2farchive.internetfreedom.in%2fpost%2ffacial-recognition-laws-in-china%2f&title=Facial%20Recognition%20Laws%20in%20China%20%23ProjectPanoptic"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Facial Recognition Laws in China #ProjectPanoptic on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2farchive.internetfreedom.in%2fpost%2ffacial-recognition-laws-in-china%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Facial Recognition Laws in China #ProjectPanoptic on whatsapp" href="https://api.whatsapp.com/send?text=Facial%20Recognition%20Laws%20in%20China%20%23ProjectPanoptic%20-%20https%3a%2f%2farchive.internetfreedom.in%2fpost%2ffacial-recognition-laws-in-china%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Facial Recognition Laws in China #ProjectPanoptic on telegram" href="https://telegram.me/share/url?text=Facial%20Recognition%20Laws%20in%20China%20%23ProjectPanoptic&url=https%3a%2f%2farchive.internetfreedom.in%2fpost%2ffacial-recognition-laws-in-china%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://archive.internetfreedom.in>Internet Freedom Foundation</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>