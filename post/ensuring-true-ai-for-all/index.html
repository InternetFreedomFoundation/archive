<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Going beyond hashtags: how to ensure AI technology truly benefits everyone | Internet Freedom Foundation</title>
<meta name=keywords content>
<meta name=description content="IFF has submitted its comments on NITI Aayog&rsquo;s draft Working Document: Enforcement Mechanisms for Responsible #AIforAll, highlighting the following issues: need for concrete  principles, role of the oversight body, robust regulation for the private sector, and risk assessment based restrictions .">
<meta name=author content="Rohin Garg">
<link rel=canonical href=https://internetfreedomfoundation.github.io/archive/post/ensuring-true-ai-for-all/>
<link crossorigin=anonymous href=/archive/assets/css/stylesheet.min.35cd0f65a15cafa92372b8313deef5960aae04b90ad722f2bbf509eb0468137e.css integrity="sha256-Nc0PZaFcr6kjcrgxPe71lgquBLkK1yLyu/UJ6wRoE34=" rel="preload stylesheet" as=style>
<link rel=preload href=/archive/iff-logo-600x250.png as=image>
<script defer crossorigin=anonymous src=/archive/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://internetfreedomfoundation.github.io/archive/iff-icon-125.png>
<link rel=icon type=image/png sizes=16x16 href=https://internetfreedomfoundation.github.io/archive/iff-icon-125.png>
<link rel=icon type=image/png sizes=32x32 href=https://internetfreedomfoundation.github.io/archive/iff-icon-125.png>
<link rel=apple-touch-icon href=https://internetfreedomfoundation.github.io/archive/iff-icon-125.png>
<link rel=mask-icon href=https://internetfreedomfoundation.github.io/archive/iff-icon-125.png>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.86.0">
<meta property="og:title" content="Going beyond hashtags: how to ensure AI technology truly benefits everyone">
<meta property="og:description" content="IFF has submitted its comments on NITI Aayog&rsquo;s draft Working Document: Enforcement Mechanisms for Responsible #AIforAll, highlighting the following issues: need for concrete  principles, role of the oversight body, robust regulation for the private sector, and risk assessment based restrictions .">
<meta property="og:type" content="article">
<meta property="og:url" content="https://internetfreedomfoundation.github.io/archive/post/ensuring-true-ai-for-all/"><meta property="og:image" content="https://internetfreedomfoundation.github.io/archive/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post">
<meta property="article:published_time" content="2020-12-14T06:44:27+00:00">
<meta property="article:modified_time" content="2020-12-14T06:44:27+00:00"><meta property="og:site_name" content="Internet Freedom Foundation">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://internetfreedomfoundation.github.io/archive/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E">
<meta name=twitter:title content="Going beyond hashtags: how to ensure AI technology truly benefits everyone">
<meta name=twitter:description content="IFF has submitted its comments on NITI Aayog&rsquo;s draft Working Document: Enforcement Mechanisms for Responsible #AIforAll, highlighting the following issues: need for concrete  principles, role of the oversight body, robust regulation for the private sector, and risk assessment based restrictions .">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://internetfreedomfoundation.github.io/archive/post/"},{"@type":"ListItem","position":2,"name":"Going beyond hashtags: how to ensure AI technology truly benefits everyone","item":"https://internetfreedomfoundation.github.io/archive/post/ensuring-true-ai-for-all/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Going beyond hashtags: how to ensure AI technology truly benefits everyone","name":"Going beyond hashtags: how to ensure AI technology truly benefits everyone","description":"IFF has submitted its comments on NITI Aayog\u0026rsquo;s draft Working Document: Enforcement Mechanisms for Responsible #AIforAll, highlighting the following issues: need for concrete  principles, role of the oversight body, robust regulation for the private sector, and risk assessment based restrictions .","keywords":[],"articleBody":"  Tl;dr NITI Aayog’s draft _Working Document: Enforcement Mechanisms for Responsible #AIforAll _ attempts to build on the the previous Working Document: Towards Responsible #AIforAll by providing enforcement mechanisms for the principles laid down in the latter. IFF has submitted its comments on the draft document highlighting the following issues: a need for concrete overarching principles, the extent of the role of the oversight body, robust regulation for the private sector, and risk assessment based restrictions for certain uses of Artificial Intelligence (AI).\nIssues As pointed out in Part 1 of the working document, the use of AI presents manifold risks:\n AI systems could pick spurious correlations in the underlying data, leading to good accuracy in test datasets but significant errors in deployment. ‘Deep Learning’ systems remain opaque ‘black boxes’, showing a high degree of accuracy even though explanations for the same elude technicians, leading to a lack of trust, accountability, and, ultimately, usage. Large scale deployment of AI leads to a large number of high frequency decisions, amplifying the impact of unfair bias. This may cause a lack of trust and disruption for social order. Technological erros may lead to large scale exclusion of citizens from services guaranteed by the state. A lack of consequences reduces incentive for responsible action, while difficulties in the allocation of liability arise in grievance redressal. AI systems may use personal data without the explicit consent of concerned persons. Advanced technology may also discern potentially sensitive information from the outputs of the system. AI systems are susceptible to attack such as manipulation of data being used to train the AI, manipulation of system to respond incorrectly to specific inputs, etc The rapid rise of AI has led to automation of a number of routine jobs, which, without adequate re-skilling and support from the state, may cause social unrest. Psychological profiling enabled by AI and the ease of spreading propaganda through online platforms has potential to cause social disharmony and disrupt democratic process.  Part 1 of the document lays down 7 core principles to mitigate these harms as well as to ensure that a common benchmark for the beneficial use of AI across different sectors is developed. These principles are:\n Principle of Safety and Reliability Principle of Equality Principle of Inclusivity and Non-discrimination Principle of Privacy and security Principle of Transparency Principle of Accountability Principle of protection and reinforcement of positive human values  What does the draft document say? The draft document clarifies the nature and roles of the oversight body for AI technology. It proposes that the oversight body be a highly participatory advisory body, and take on the following roles:\n Manage and update AI principles laid down Research into the various issues related to AI Provide clarity on design structures, standards, guidelines, etc Promote development and access to AI data and technology tools Help create awareness about responsible AI among various stakeholders Coordinate between different sectoral regulators Represent India in international dialogues on AI  The draft document aso specifies the need for an AI Ethics Committee in public sector bodies to handle the procurement, development, operations phase of AI systems and to ensure adherence to the Responsible AI principles. Self regulation is recommended for the private sector, with accountability for ethics being assigned to existing leadership.\nEnsuring that AI truly works for All Our recommendations are based on 4 key issues:\n Need for concrete overarching principles: Part 1 of the working document lists certain principles as principles for responsible AI. However, obscurity still persists with regards to the implication of adoption of these principles in the regulatory framework. Thus, we believe that there is a need to spell out both the detailed meaning of the principles which will work as a foundation to build enforcement mechanisms on as well as the implications of adopting them for regulatory frameworks. Greater role for oversight body: The draft document proposes the Council for Ethics and Technology as an oversight mechanism, which will be a “highly participatory advisory body”. We appreciate the formation of such an oversight body, due to the absence of clear laws and legal requirements governing AI, the Council for Ethics and Technology should have more than mere advisory functions and perform a regulatory assurance role, in conjunction with any forthcoming data authority, under the Personal Data Protection Bill, 2019. This should be specifically with the nature of any AI based system that impacts any legal right of a person. Robust regulation for the private sector: The draft document proposes voluntary self-regulation as a starting point for regulating AI in the private sector in India. While self-regulatory efforts are commendable, they should not be made a substitute for laws needed to closely monitor AI. In order to foster a healthy AI ecosystem, soft laws of self-regulation need to be complemented with strict provisions to govern high risk applications of AI. Risk assessment based restrictions for different sectors: All AI is not the same since the term envelopes within its multiple technologies. Thus, on the basis of a sector specific risk-assessment study, proportionate restrictions on the use of AI should be in place until an overarching, regulatory framework has been developed.  Risk Based Assessment - AI in Facial Recognition Technology Procedure In our submission, we provided a template risk based assessment for illustrative purposes, which was based on the following procedure:\n Step 1: The Council must categorize use cases of AI into the 4 types of Algorithmic Systems based on the AI Now Institute’s categorization of algorithmic systems used in their 2018 ‘Algorithmic Accountability Policy Toolkit’. Step 2: The Council must assess the type of data collected by the AI into anonymous data, personal and sensitive personal data,, Step 3: Based on type of data, risk assessment may be done with sensitive personal data having the highest risk assessment and anonymous data the lowest (Scale of 1-3 with 3 being the highest). Step 4: Based on the level of risk assessment combined with the type of algorithmic system, the regulation framework may be designed by the Council.  The dangers of AI in Facial Recognition Technology Here, we would like to address the use of AI for facial recognition technology (FRT). FRT which collects sensitive personal data for criminal justice purposes should be banned from being developed and deployed in India. Under IFF’s Project Panoptic, we have been mapping FRT systems across the country which are being developed and deployed without any regulatory framework as well as without any public awareness or transparency pertaining to how they will be used.\nBy our estimation, there are currently 19 different FRT projects which are being used by Police and Security/Intelligence agencies at the Central and State level in different stages of development and deployment. This is being done in the absence of a personal data protection law/regime as well as any specific regulation for FRT. The harms of such use are manifold:\n One sort of harm results from the implementation of a faulty FRT system wherein the technology is inaccurate in identifying and matching faces from a photo/video to an existing database. Such inaccuracy could lead to a false positive result from the FRT. This may lead to discrimination and strengthening of existing biases. In the present context, a false positive by a FRT system being used by the police could lead to wrongful arrest and detention of an innocent person. Another type of harm results from the implementation of an accurate FRT system wherein the technology achieves 100% accuracy in identifying and matching faces from a photo/video to an existing database. While there have been claims of a fully accurate FRT system, none of these claims have been corroborated by independent review and audit. The National Institute of Standards and Technology (NIST) has extensively tested FRT systems for ‘1:1’ verification and ‘1:many’ identification and how accuracy of these systems vary across demographic groups. These independent studies have concluded that, currently, no FRT system has 100% accuracy. Probe images for FRT systems are often collected by the police through CCTV cameras installed in public spaces. Individuals in a CCTV surveilled area may be aware that they are under surveillance but the assumption is that this surveillance is temporary. Use of CCTV in conjunction with FRT would mean their images will be stored for a longer period of time, if not permanently. This data will also be used to extract particular data points such as the facial features and other biometrics (sensitive personal data) which the individual has not consented to sharing when entering a CCTV surveilled zone and these data points can be used to track future movements of the person. Therefore, integration of FRT with a network of CCTV cameras would make real time mass surveillance extremely easy.  Goes against standards set by the Supreme Court We would like to emphasise that use of FRT for criminal justice purposes goes beyond the standards laid down by the Hon’ble Supreme Court in Justice K.S. Puttaswamy vs Union of India (2017 10 SCC 1). The landmark decision lays down certain thresholds which the State must conform to to justify intrusions by the State into people’s right to privacy protected under Article 21 of the Constitution of India. These thresholds are:\n Legality: Where the intrusion must take place in the presence of a defined regime of law i.e. there must be an anchoring legislation, with a clear set of provisions. As we know, there is no anchoring legislation in place to regulate the use of FRT by the police. Additionally, we do not have a data protection regime to oversee the collection, processing and storage of data collected by these systems. Necessity: Which justifies that the restriction to people’s privacy (in this case data collection and sharing) is needed in a democratic society to fulfill a legitimate state aim. Use of FRT by the police has been justified based on reasons pertaining to security of the public and the country itself, with proponents saying it will enable automatic identification and verification through criminal databases. This characterisation is based on the faulty assumption that facial recognition technology is accurate, when ongoing research in the field has shown that completely accurate facial recognition technology has not been developed yet. Use of such inaccurate technology, especially for criminal prosecution, could thus result in a false positive. Proportionality: Where the Government must show among other things that the measure being undertaken has a rational nexus with the objective. FRT contemplates the collecting of sensitive personal information, intimate information of all individuals in the absence of any reasonable suspicion by collecting images and videos from a scene of crime. This could cast a presumption of criminality on a broad set of people. Collecting sensitive personal information of all individuals who were present at the scene of crime creates a presumption of criminality which is disproportionate to the objective it aims to achieve. Procedural safeguards: Where there is an appropriate independent institutional mechanism, with in-built procedural safeguards aligned with standards of procedure established by law which are just, fair and reasonable to prevent abuse. In the absence of any checks and balances, function creep becomes an immediate problem wherein the issue of FRT being used for functions more than its stated purpose becomes a reality. Use of FRT without safeguards could result in illegal state-sponsored mass surveillance which would have a chilling effect on fundamental rights such right to freedom of expression, freedom of movement and freedom of association which are guaranteed in the Constitution.  Recommended Restriction Use of this technology has raised concerns not only in India but also abroad with various civil society organisations such as the Electronic Frontier Foundation, the Algorithmic Justice League and Amnesty International calling for ban on the use of this technology. Calls for a total ban have been gaining momentum due to the fear that use of facial recognition by the police and security/intelligence agencies will not only lead to violation of the rights to privacy and freedom of speech and expression but also lead to human rights violations by helping to increase systemic bias against already marginalised communities. The impact on marginalised communities gains special importance for us locally due to the wide inequality and diversity present in our society. Thus, we recommend that the use of FRT be banned.\nImportant Documents  NITI Aayog’s draft Working Document: Enforcement Mechanisms for Responsible #AIforAll (link) NITI Aayog’s Working Document: Towards Responsible #AIforAll (link) IFF’s comments on the draft document (link) IFF’s Project Panoptic FRT Tracker (link)  ","wordCount":"2075","inLanguage":"en","datePublished":"2020-12-14T06:44:27Z","dateModified":"2020-12-14T06:44:27Z","author":{"@type":"Person","name":"Rohin Garg"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://internetfreedomfoundation.github.io/archive/post/ensuring-true-ai-for-all/"},"publisher":{"@type":"Organization","name":"Internet Freedom Foundation","logo":{"@type":"ImageObject","url":"https://internetfreedomfoundation.github.io/archive/iff-icon-125.png"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<noscript>
<style type=text/css>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://internetfreedomfoundation.github.io/archive/ accesskey=h title="IFF (Alt + H)">
<img src=/archive/iff-logo-600x250.png alt=logo aria-label=logo height=40>IFF</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://internetfreedomfoundation.github.io/archive/archives title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://internetfreedomfoundation.github.io/archive/about/ title=About>
<span>About</span>
</a>
</li>
<li>
<a href=https://internetfreedomfoundation.github.io/archive/categories/ title=Categories>
<span>Categories</span>
</a>
</li>
<li>
<a href=https://internetfreedomfoundation.github.io/archive/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Going beyond hashtags: how to ensure AI technology truly benefits everyone
</h1>
<div class=post-meta>December 14, 2020&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Rohin Garg&nbsp;|&nbsp;<a href=https://github.com/InternetFreedomFoundation/archive/tree/main/content/post/ensuring-true-ai-for-all.md rel="noopener noreferrer" target=_blank>Suggest Changes</a>
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<div class=details>Table of Contents</div>
</summary>
<div class=inner><ul>
<li>
<a href=#tldr aria-label=Tl;dr>Tl;dr</a></li>
<li>
<a href=#issues aria-label=Issues>Issues</a></li>
<li>
<a href=#what-does-the-draft-document-say aria-label="What does the draft document say?">What does the draft document say?</a></li>
<li>
<a href=#ensuring-that-ai-truly-works-for-all aria-label="Ensuring that AI truly works for All">Ensuring that AI truly works for All</a></li>
<li>
<a href=#risk-based-assessment---ai-in-facial-recognition-technology aria-label="Risk Based Assessment - AI in Facial Recognition Technology">Risk Based Assessment - AI in Facial Recognition Technology</a><ul>
<li>
<a href=#procedure aria-label=Procedure>Procedure</a></li>
<li>
<a href=#the-dangers-of-ai-in-facial-recognition-technology aria-label="The dangers of AI in Facial Recognition Technology">The dangers of AI in Facial Recognition Technology</a></li>
<li>
<a href=#goes-against-standards-set-by-the-supreme-court aria-label="Goes against standards set by the Supreme Court">Goes against standards set by the Supreme Court</a></li>
<li>
<a href=#recommended-restriction aria-label="Recommended Restriction">Recommended Restriction</a></li>
<li>
<a href=#important-documents aria-label="Important Documents">Important Documents</a>
</li>
</ul>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><figure>
<img loading=lazy src=https://internetfreedom.in/content/images/2020/12/AI-for-all.png>
</figure>
<h2 id=tldr>Tl;dr<a hidden class=anchor aria-hidden=true href=#tldr>#</a></h2>
<p>NITI Aayog&rsquo;s draft _<a href=https://ourgovdotin.files.wordpress.com/2020/11/niti-working-document-enforcement-mechanisms-for-responsible-aiforall.pdf>Working Document: Enforcement Mechanisms for Responsible #AIforAll</a> _ attempts to build on the the previous <em>Working Document: Towards Responsible #AIforAll</em> by providing enforcement mechanisms for the principles laid down in the latter. IFF has submitted its comments on the draft document highlighting the following issues: a need for concrete overarching principles, the extent of the role of the oversight body, robust regulation for the private sector, and risk assessment based restrictions for certain uses of Artificial Intelligence (AI).</p>
<h2 id=issues>Issues<a hidden class=anchor aria-hidden=true href=#issues>#</a></h2>
<p>As pointed out in <a href=https://niti.gov.in/sites/default/files/2020-07/Responsible-AI.pdf>Part 1</a> of the working document, the use of AI presents manifold risks:</p>
<ol>
<li>AI systems could pick spurious correlations in the underlying data, leading to good accuracy in test datasets but <strong>significant errors in deployment</strong>.</li>
<li>&lsquo;Deep Learning&rsquo; systems remain opaque &lsquo;black boxes&rsquo;, showing a high degree of accuracy even though explanations for the same elude technicians, leading to a <strong>lack of trust, accountability, and, ultimately, usage</strong>.</li>
<li>Large scale deployment of AI leads to a large number of high frequency decisions, <strong>amplifying the impact of unfair bias</strong>. This may cause a lack of trust and disruption for social order.</li>
<li>Technological erros may lead to <strong>large scale exclusion of citizens</strong> from services guaranteed by the state.</li>
<li>A lack of consequences <strong>reduces incentive for responsible action</strong>, while <strong>difficulties in the allocation of liability</strong> arise in grievance redressal.</li>
<li>AI systems may use personal data <strong>without the explicit consent</strong> of concerned persons. Advanced technology may also <strong>discern potentially sensitive information</strong> from the outputs of the system.</li>
<li>AI systems are <strong>susceptible to attack</strong> such as manipulation of data being used to train the AI, manipulation of system to respond incorrectly to specific inputs, etc</li>
<li>The rapid rise of AI has led to <strong>automation of a number of routine jobs</strong>, which, without adequate re-skilling and support from the state, may cause social unrest.</li>
<li><strong>Psychological profiling</strong> enabled by AI and the e<strong>ase of spreading propaganda</strong> through online platforms has potential to cause social disharmony and disrupt democratic process.</li>
</ol>
<p>Part 1 of the document lays down 7 core principles to mitigate these harms as well as to ensure that a common benchmark for the beneficial use of AI across different sectors is developed. These principles are:</p>
<ul>
<li>Principle of Safety and Reliability</li>
<li>Principle of Equality</li>
<li>Principle of Inclusivity and Non-discrimination</li>
<li>Principle of Privacy and security</li>
<li>Principle of Transparency</li>
<li>Principle of Accountability</li>
<li>Principle of protection and reinforcement of positive human values</li>
</ul>
<h2 id=what-does-the-draft-document-say>What does the draft document say?<a hidden class=anchor aria-hidden=true href=#what-does-the-draft-document-say>#</a></h2>
<p>The draft document clarifies the nature and roles of the oversight body for AI technology. It proposes that the oversight body be a highly participatory advisory body, and take on the following roles:</p>
<ul>
<li>Manage and update AI principles laid down</li>
<li>Research into the various issues related to AI</li>
<li>Provide clarity on design structures, standards, guidelines, etc</li>
<li>Promote development and access to AI data and technology tools</li>
<li>Help create awareness about responsible AI among various stakeholders</li>
<li>Coordinate between different sectoral regulators</li>
<li>Represent India in international dialogues on AI</li>
</ul>
<p>The draft document aso specifies the need for an AI Ethics Committee in public sector bodies to handle the procurement, development, operations phase of AI systems and to ensure adherence to the Responsible AI principles. Self regulation is recommended for the private sector, with accountability for ethics being assigned to existing leadership.</p>
<h2 id=ensuring-that-ai-truly-works-for-all>Ensuring that AI truly works for All<a hidden class=anchor aria-hidden=true href=#ensuring-that-ai-truly-works-for-all>#</a></h2>
<p>Our recommendations are based on 4 key issues:</p>
<ol>
<li><strong>Need for concrete overarching principles:</strong> Part 1 of the working document lists certain principles as principles for responsible AI. However, obscurity still persists with regards to the implication of adoption of these principles in the regulatory framework. Thus, we believe that there is a need to spell out both the detailed meaning of the principles which will work as a foundation to build enforcement mechanisms on as well as the implications of adopting them for regulatory frameworks.</li>
<li><strong>Greater role for oversight body:</strong> The draft document proposes the Council for Ethics and Technology as an oversight mechanism, which will be a <em>“highly participatory advisory body”</em>. We appreciate the formation of such an oversight body, due to the absence of clear laws and legal requirements governing AI, the Council for Ethics and Technology should have more than mere advisory functions and perform a regulatory assurance role, in conjunction with any forthcoming data authority, under the Personal Data Protection Bill, 2019. This should be specifically with the nature of any AI based system that impacts any legal right of a person.</li>
<li><strong>Robust regulation for the private sector:</strong> The draft document proposes voluntary self-regulation as a starting point for regulating AI in the private sector in India. While self-regulatory efforts are commendable, they should not be made a substitute for laws needed to closely monitor AI. In order to foster a healthy AI ecosystem, soft laws of self-regulation need to be complemented with strict provisions to govern high risk applications of AI.</li>
<li><strong>Risk assessment based restrictions for different sectors</strong>: All AI is not the same since the term envelopes within its multiple technologies. Thus, on the basis of a sector specific risk-assessment study, proportionate restrictions on the use of AI should be in place until an overarching, regulatory framework has been developed.</li>
</ol>
<h2 id=risk-based-assessment---ai-in-facial-recognition-technology>Risk Based Assessment - AI in Facial Recognition Technology<a hidden class=anchor aria-hidden=true href=#risk-based-assessment---ai-in-facial-recognition-technology>#</a></h2>
<h3 id=procedure>Procedure<a hidden class=anchor aria-hidden=true href=#procedure>#</a></h3>
<p>In our submission, we provided a template risk based assessment for illustrative purposes, which was based on the following procedure:</p>
<ul>
<li><strong>Step 1</strong>: The Council must categorize use cases of AI into the 4 types of Algorithmic Systems based on the AI Now Institute’s categorization of algorithmic systems used in their 2018 ‘Algorithmic Accountability Policy Toolkit’.</li>
<li><strong>Step 2</strong>: The Council must assess the type of data collected by the AI into anonymous data, personal and sensitive personal data,,</li>
<li><strong>Step 3</strong>: Based on type of data, risk assessment may be done with sensitive personal data having the highest risk assessment and anonymous data the lowest (Scale of 1-3 with 3 being the highest).</li>
<li><strong>Step 4</strong>: Based on the level of risk assessment combined with the type of algorithmic system, the regulation framework may be designed by the Council.</li>
</ul>
<h3 id=the-dangers-of-ai-in-facial-recognition-technology>The dangers of AI in Facial Recognition Technology<a hidden class=anchor aria-hidden=true href=#the-dangers-of-ai-in-facial-recognition-technology>#</a></h3>
<p>Here, we would like to address the use of AI for facial recognition technology (FRT). FRT which collects sensitive personal data for criminal justice purposes should be banned from being developed and deployed in India. Under IFF’s <a href=https://panoptic.frappe.cloud/>Project Panoptic</a>, we have been mapping FRT systems across the country which are being developed and deployed without any regulatory framework as well as without any public awareness or transparency pertaining to how they will be used.</p>
<p>By our estimation, there are currently 19 different FRT projects which are being used by Police and Security/Intelligence agencies at the Central and State level in different stages of development and deployment. This is being done in the absence of a personal data protection law/regime as well as any specific regulation for FRT. The harms of such use are manifold:</p>
<ul>
<li>One sort of harm results from the implementation of a faulty FRT system wherein the <strong>technology is inaccurate in identifying and matching faces</strong> from a photo/video to an existing database. Such inaccuracy could lead to a false positive result from the FRT. This may lead to discrimination and strengthening of existing biases. In the present context, a false positive by a FRT system being used by the police could lead to wrongful arrest and detention of an innocent person.</li>
<li>Another type of harm results from the implementation of an accurate FRT system wherein <strong>the technology achieves 100% accuracy in identifying and matching faces</strong> from a photo/video to an existing database. While there have been claims of a fully accurate FRT system, none of these claims have been corroborated by independent review and audit. The National Institute of Standards and Technology (NIST) has extensively tested FRT systems for ‘1:1’ verification and ‘1:many’ identification and how accuracy of these systems vary across demographic groups. These independent studies have concluded that, currently, no FRT system has 100% accuracy.</li>
<li>Probe images for FRT systems are often collected by the police t<strong>hrough CCTV cameras installed in public spaces</strong>. Individuals in a CCTV surveilled area may be aware that they are under surveillance but the assumption is that this surveillance is temporary. Use of CCTV in conjunction with FRT would mean their images will be stored for a longer period of time, if not permanently. This data will also be used to extract particular data points such as the facial features and other biometrics (sensitive personal data) which the individual has not consented to sharing when entering a CCTV surveilled zone and these data points can be used to track future movements of the person. Therefore, integration of FRT with a network of CCTV cameras would make <strong>real time mass surveillance extremely easy</strong>.</li>
</ul>
<h3 id=goes-against-standards-set-by-the-supreme-court>Goes against standards set by the Supreme Court<a hidden class=anchor aria-hidden=true href=#goes-against-standards-set-by-the-supreme-court>#</a></h3>
<p>We would like to emphasise that use of FRT for criminal justice purposes goes beyond the standards laid down by the Hon’ble Supreme Court in <em>Justice K.S. Puttaswamy vs Union of India</em> (2017 10 SCC 1). The landmark decision lays down certain thresholds which the State must conform to to justify intrusions by the State into people’s right to privacy protected under Article 21 of the Constitution of India. These thresholds are:</p>
<ol>
<li><strong>Legality</strong>: <em>Where the intrusion must take place in the presence of a defined regime of law i.e. there must be an anchoring legislation, with a clear set of provisions.</em> As we know, there is no anchoring legislation in place to regulate the use of FRT by the police. Additionally, we do not have a data protection regime to oversee the collection, processing and storage of data collected by these systems.</li>
<li><strong>Necessity</strong>: <em>Which justifies that the restriction to people’s privacy (in this case data collection and sharing) is needed in a democratic society to fulfill a legitimate state aim.</em> Use of FRT by the police has been justified based on reasons pertaining to security of the public and the country itself, with proponents saying it will enable automatic identification and verification through criminal databases. This characterisation is based on the faulty assumption that facial recognition technology is accurate, when ongoing research in the field has shown that completely accurate facial recognition technology has not been developed yet. Use of such inaccurate technology, especially for criminal prosecution, could thus result in a false positive.</li>
<li><strong>Proportionality</strong>: <em>Where the Government must show among other things that the measure being undertaken has a rational nexus with the objective.</em> FRT contemplates the collecting of sensitive personal information, intimate information of all individuals in the absence of any reasonable suspicion by collecting images and videos from a scene of crime. This could cast a presumption of criminality on a broad set of people. Collecting sensitive personal information of all individuals who were present at the scene of crime creates a presumption of criminality which is disproportionate to the objective it aims to achieve.</li>
<li><strong>Procedural safeguards</strong>: <em>Where there is an appropriate independent institutional mechanism, with in-built procedural safeguards aligned with standards of procedure established by law which are just, fair and reasonable to prevent abuse.</em> In the absence of any checks and balances, function creep becomes an immediate problem wherein the issue of FRT being used for functions more than its stated purpose becomes a reality. Use of FRT without safeguards could result in illegal state-sponsored mass surveillance which would have a chilling effect on fundamental rights such right to freedom of expression, freedom of movement and freedom of association which are guaranteed in the Constitution.</li>
</ol>
<h3 id=recommended-restriction>Recommended Restriction<a hidden class=anchor aria-hidden=true href=#recommended-restriction>#</a></h3>
<p>Use of this technology has raised concerns not only in India but also abroad with various civil society organisations such as the Electronic Frontier Foundation, the Algorithmic Justice League and Amnesty International calling for ban on the use of this technology. Calls for a total ban have been gaining momentum due to the fear that use of facial recognition by the police and security/intelligence agencies will not only lead to violation of the rights to privacy and freedom of speech and expression but also lead to human rights violations by helping to increase systemic bias against already marginalised communities. The impact on marginalised communities gains special importance for us locally due to the wide inequality and diversity present in our society. Thus, we recommend that the use of FRT be banned.</p>
<h3 id=important-documents>Important Documents<a hidden class=anchor aria-hidden=true href=#important-documents>#</a></h3>
<ol>
<li>NITI Aayog&rsquo;s draft <em>Working Document: Enforcement Mechanisms for Responsible #AIforAll</em> (<a href=https://ourgovdotin.files.wordpress.com/2020/11/niti-working-document-enforcement-mechanisms-for-responsible-aiforall.pdf>link</a>)</li>
<li>NITI Aayog&rsquo;s <em>Working Document: Towards Responsible #AIforAll</em> (<a href=https://niti.gov.in/sites/default/files/2020-07/Responsible-AI.pdf>link</a>)</li>
<li>IFF&rsquo;s comments on the draft document (<a href="https://drive.google.com/file/d/1CKvQ3pSSyDjce952u-qedS30ySkze_CS/view?usp=sharing">link</a>)</li>
<li>IFF&rsquo;s Project Panoptic FRT Tracker (<a href=https://panoptic.frappe.cloud/>link</a>)</li>
</ol>
</div>
<footer class=post-footer>
<nav class=paginav>
<a class=prev href=https://internetfreedomfoundation.github.io/archive/post/iff-intervenes-madras-hc-pil-ott-regulation/>
<span class=title>« Prev Page</span>
<br>
<span>IFF intervenes in Madras HC PIL seeking censorship on online streaming platforms #LetUsChill</span>
</a>
<a class=next href=https://internetfreedomfoundation.github.io/archive/post/worker-surveillance-through-labour-reforms/>
<span class=title>Next Page »</span>
<br>
<span>Comments on the Draft Social Security Rules to safeguard worker's rights #SaveOurPrivacy</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Going beyond hashtags: how to ensure AI technology truly benefits everyone on twitter" href="https://twitter.com/intent/tweet/?text=Going%20beyond%20hashtags%3a%20how%20to%20ensure%20AI%20technology%20truly%20benefits%20everyone&url=https%3a%2f%2finternetfreedomfoundation.github.io%2farchive%2fpost%2fensuring-true-ai-for-all%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Going beyond hashtags: how to ensure AI technology truly benefits everyone on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2finternetfreedomfoundation.github.io%2farchive%2fpost%2fensuring-true-ai-for-all%2f&title=Going%20beyond%20hashtags%3a%20how%20to%20ensure%20AI%20technology%20truly%20benefits%20everyone&summary=Going%20beyond%20hashtags%3a%20how%20to%20ensure%20AI%20technology%20truly%20benefits%20everyone&source=https%3a%2f%2finternetfreedomfoundation.github.io%2farchive%2fpost%2fensuring-true-ai-for-all%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Going beyond hashtags: how to ensure AI technology truly benefits everyone on reddit" href="https://reddit.com/submit?url=https%3a%2f%2finternetfreedomfoundation.github.io%2farchive%2fpost%2fensuring-true-ai-for-all%2f&title=Going%20beyond%20hashtags%3a%20how%20to%20ensure%20AI%20technology%20truly%20benefits%20everyone"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Going beyond hashtags: how to ensure AI technology truly benefits everyone on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2finternetfreedomfoundation.github.io%2farchive%2fpost%2fensuring-true-ai-for-all%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Going beyond hashtags: how to ensure AI technology truly benefits everyone on whatsapp" href="https://api.whatsapp.com/send?text=Going%20beyond%20hashtags%3a%20how%20to%20ensure%20AI%20technology%20truly%20benefits%20everyone%20-%20https%3a%2f%2finternetfreedomfoundation.github.io%2farchive%2fpost%2fensuring-true-ai-for-all%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Going beyond hashtags: how to ensure AI technology truly benefits everyone on telegram" href="https://telegram.me/share/url?text=Going%20beyond%20hashtags%3a%20how%20to%20ensure%20AI%20technology%20truly%20benefits%20everyone&url=https%3a%2f%2finternetfreedomfoundation.github.io%2farchive%2fpost%2fensuring-true-ai-for-all%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://internetfreedomfoundation.github.io/archive/>Internet Freedom Foundation</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)">
<button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</button>
</a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>