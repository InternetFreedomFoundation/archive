<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System | Internet Freedom Foundation</title>
<meta name=keywords content="facial recognition,Project Panoptic,WatchtheWatchmen,Surveillance,SaveOurPrivacy">
<meta name=description content="In the fourth part of our &ldquo;Watch the Watchmen&rdquo; series which aims to develop and use a national database of photographs which is to be used in conjunction with a facial recognition technology system by Central and State security agencies to swiftly identify criminals.">
<meta name=author content="Anushka Jain">
<link rel=canonical href=https://archive.internetfreedom.in/post/watch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.b9ff4cc257e914dab489bd18086151800e18f91456a5174bf28489210227a659.css integrity="sha256-uf9MwlfpFNq0ib0YCGFRgA4Y+RRWpRdL8oSJIQInplk=" rel="preload stylesheet" as=style>
<link rel=preload href=/archive/iff-logo-600x250.png as=image>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://archive.internetfreedom.in/archive/iff-icon-125.png>
<link rel=icon type=image/png sizes=16x16 href=https://archive.internetfreedom.in/archive/iff-icon-125.png>
<link rel=icon type=image/png sizes=32x32 href=https://archive.internetfreedom.in/archive/iff-icon-125.png>
<link rel=apple-touch-icon href=https://archive.internetfreedom.in/archive/iff-icon-125.png>
<link rel=mask-icon href=https://archive.internetfreedom.in/archive/iff-icon-125.png>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.87.0">
<meta property="og:title" content="Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System">
<meta property="og:description" content="In the fourth part of our &ldquo;Watch the Watchmen&rdquo; series which aims to develop and use a national database of photographs which is to be used in conjunction with a facial recognition technology system by Central and State security agencies to swiftly identify criminals.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://archive.internetfreedom.in/post/watch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system/"><meta property="og:image" content="https://archive.internetfreedom.in/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post">
<meta property="article:published_time" content="2020-10-07T04:30:00+00:00">
<meta property="article:modified_time" content="2020-10-07T04:30:00+00:00"><meta property="og:site_name" content="Internet Freedom Foundation">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://archive.internetfreedom.in/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E">
<meta name=twitter:title content="Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System">
<meta name=twitter:description content="In the fourth part of our &ldquo;Watch the Watchmen&rdquo; series which aims to develop and use a national database of photographs which is to be used in conjunction with a facial recognition technology system by Central and State security agencies to swiftly identify criminals.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://archive.internetfreedom.in/post/"},{"@type":"ListItem","position":3,"name":"Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System","item":"https://archive.internetfreedom.in/post/watch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System","name":"Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System","description":"In the fourth part of our \u0026ldquo;Watch the Watchmen\u0026rdquo; series which aims to develop and use a national database of photographs which is to be used in conjunction with a facial recognition technology system by Central and State security agencies to swiftly identify criminals.","keywords":["facial recognition","Project Panoptic","WatchtheWatchmen","Surveillance","SaveOurPrivacy"],"articleBody":"  tl;dr The National Automated Facial Recognition System (AFRS) is being developed by the National Crime Records Bureau (NCRB) under the Ministry of Home Affairs. The project aims to develop and use a national database of photographs which is to be used in conjunction with a facial recognition technology system by Central and State security agencies.\nHistory The NCRB first released the Request for Proposals (RFP) (Document Reference: 02/001).calling for bids for the creation of AFRS on 28 June, 2019 Initially, the deadline for submission of bids was on August 16, 2019 (Read our first post on the subject here). However, the deadline was extended multiple times due to reported administrative reasons. Finally, the RFP was recalled and cancelled. A new revised version of the RFP [Document Reference: 02/001 (Revised)] was issued on June 22, 2020.\nThe current deadline for the submission of bids is October 8, 2020.\nThe estimated budget of the project is INR 308 crore.\nWhat is AFRS? The RFP invites bids for the creation of a National Automated Facial Recognition System (AFRS) to further create a national database of photographs. According to the RFP, this database is purported to be used to swiftly identify criminals by gathering existing data from various other databases like:\n Passport database under the Ministry of External Affairs, Crime and Criminal Tracking Network and Systems (CCTNS) by the National Crime Records Bureau(NCRB) under the Ministry of Home Affairs (MHA), Interoperable Criminal Justice System (ICJS) by the NCRB under the MHA , Women and Child Development Ministry’s KhoyaPaya Portal, Automated Fingerprint Identification System (AFIS) by the NCRB under the MHA Any other image database available with police/other entities.  To identify criminals, scene of crime (SOC) images and videos will be matched with the abovementioned databases by using facial recognition technology. Face recognition systems use computer algorithms to pick out specific, distinctive details about a person’s face. These details, such as distance between the eyes or shape of the chin, are then converted into a mathematical representation and compared to data on other faces collected in a face recognition database. The data about a particular face is often called a face template and is distinct from a photograph because it’s designed to only include certain details that can be used to distinguish one face from another.\nWhat could go wrong? Identification happens when FRT is used to identify an individual from a pool of many people. This kind of 1: many FRT based identification is typically used for security and surveillance purposes. Verification, on the other hand, occurs when an image is compared to another image from an existing database in order to verify that the individual is who he/she claims to be, i.e., authentication of identity on a 1:1 basis.\nImplementation of a Faulty FRT System Claims relating to accuracy of FRT systems are routinely exaggerated and the real numbers leave much to be desired. The implementation of such faulty FRT systems would lead to high rates of false positives and false negatives in this recognition process.\n A false positive occurs when FRT gives an incorrect positive result wherein the system misidentifies an individual as someone he/she is not. This may lead to discrimination and strengthening of existing biases. For instance, ACLU found that Amazon’s facial recognition software “Rekognition” incorrectly matched 28 members of the US Congress with people who had been arrested for committing a crime. Of those members who were incorrectly matched, 40% were people of color which is a disproportionate number since people of color make up only 20% of the US Congress. A false negative occurs when the FRT gives an incorrect negative result wherein the system is unable to recognize an individual or authenticate his/her identity. This may lead to arbitrary exclusion of an individual from government schemes and benefits. Failure of biometric based authentication under Aadhaar has led to many people being excluded from receiving essential government services and even led to starvation deaths. Such problems will be further aggravated by an inaccurate FRT system.  The AFRS is being developed and deployed by the government without any technical standards in place which may lead to faulty systems being implemented. Once in place, it would be very difficult for it to be reconciled with future technical standards and damage like discrimination and exclusion would be impossible to undo. In the revised RFP, there is no mention of the international standards which were included in the original RFP which had to be complied with as a technical requirement. The reason behind the exclusion of these standards is unclear and raises the question of why necessary standards of technical requirements are being diluted.\nImplementation of an Accurate FRT System While there have been claims of a fully accurate FRT system, none of these claims have been corroborated by independent review and audit. The National Institute of Standards and Technology (NIST) has extensively tested FRT systems for 1:1 verification and 1:many identification and how accuracy of these systems vary across demographic groups. These independent studies have concluded that currently, no FRT system has 100% accuracy.\nAn accurate FRT system would hypothetically have a 100% success rate in 1:1 verification and/or 1:many identification. However, it will come with its own ominous connotations, the most problematic of which may be state led mass surveillance and difficulty for outside actors to counter-challenge government decisions.\nProbe images for FRT systems are often collected by the police through CCTV cameras installed in public spaces. Individuals in a CCTV surveilled area may be aware that they are under surveillance but the assumption is that this surveillance is temporary. Use of CCTV in conjunction with FRT would mean their images will be stored for a longer period of time, if not permanently. This data will also be used to extract particular data points such as the facial features and other biometrics which the individual has not consented to sharing when entering a CCTV surveilled zone and these data points can be used to track future movements of the person. Therefore, integration of FRT with a network of CCTV cameras would make real time surveillance extremely easy.\nOne of the most important changes which have been made in the revised RFP is that it now states that the project “does not involve the installation of CCTV camera nor will it connect to any existing CCTV camera anywhere”. This is a departure from the original RFP wherein CCTV integration had been included as a functional requirement.\nHowever in the revised RFP, a new data source “Scene of Crime images/videos” has been introduced for input into the AFRS database. This inclusion is at odds with the previous assertion made in the RFP - that integration of CCTVs will not take place. Deletion of CCTV camera footage as a data source leaves a gap in the functional architecture of AFRS and the RFP fails to satisfactorily account for its replacement. The RFP also fails to mention how the data and subsequent analysis/ information which is obtained through AFRS will be presented and utilized in a court of law, i.e., the nature of the evidence obtained from AFRS and its admissibility as pertaining to its reliability in courts.\nDeployment of AFRS without adequate legal safeguards is deeply troubling. Specific laws with regard to FRT and personal data protection do not currently exist in India. While a flawed Personal Data Protection Bill has been introduced in the Parliament (read more here), there is uncertainty about when it will be enacted and implemented and how effective it will be in protecting the personal data of individuals. Under the current version of the Bill, wide exceptions have been provided to the Government for surveillance related activities. A strong data protection legislation is needed to hold these FRT systems accountable in terms of collection, storage and usage of data including sharing of data across government agencies and with third parties.\nThe implementation of an accurate FRT system would also violate fundamental rights by facilitating mass surveillance. For instance, there will be a chilling effect on the right to freedom of speech and expression because people will be wary of being prosecuted in case they express anti-government sentiments. Further, the right to freedom of movement would be hampered as mass surveillance would allow the government to track the movements of individuals in real time across the country. Finally, the right to privacy will be violated as sensitive personal data which is collected by these FRT systems will be used by the Government without the informed consent of the individual. This would also hamper the individual from exercising the liberty to share their information in some contexts and remain anonymous in others according to their individual choice.\nAs per the Hon’ble Supreme Court’s decision in Justice K.S. Puttaswamy vs Union of India (2017 10 SCC 1) any justifiable intrusion by the State into people’s right to privacy protected under Article 21 of the Constitution must conform to certain thresholds. These thresholds are:\nA. Legality Where the intrusion must take place a defined regime of law i.e. there must be an anchoring legislation, with a clear set of provisions. As pointed out in our previous legal notice as well, there is no anchoring legislation which allows for and regulates the use of AFRS. In the absence of such a framework and safeguards, the first requirement for lawful restriction on the right to privacy is not met.\nB. Necessity Which justifies that the restriction to people’s privacy (in this case data collection and sharing) is needed in a democratic society to fulfill a legitimate state aim. In the RFP, it is stated that the need for AFRS arises because it will enable automatic identification and verification through criminal databases which would help investigation of crime and tracking and detection of criminals.\nThis characterisation is based on a faulty assumption that facial recognition technology is accurate and would provide speedy and correct results. However, ongoing research in the field has shown that facial recognition technology which is completely accurate has not been developed yet. Use of such inaccurate technology, especially for criminal prosecution, could thus result in a false positive, i.e., misidentification of an innocent individual as a suspect in a crime. Thus, AFRS fails to meet the requirement of necessity as laid down by the Supreme Court in the Puttaswamy judgment.\nC. Proportionality Where the Government must show among other things that the measure being undertaken has a rational nexus with the objective. The AFRS contemplates collecting sensitive personal information, intimate information of all individuals in the absence of any reasonable suspicion by collecting images and videos from a scene of crime. This could cast a presumption of criminality on a broad set of people. In the Supreme Court’s decision in K.S. Puttaswamy v. Union of India (2019) 1 SCC 1 or the Aadhaar judgment , the Hon’ble Supreme Court held that:\n “[u]nder the garb of prevention of money laundering or black money, there cannot be such a sweeping provision which targets every resident of the country as a suspicious person”\n While this statement was made in the context of rejecting the mandatory linkage of Aadhaar with bank accounts to counter money laundering, it clearly shows that imposition of such a restriction on the entire population, without any evidence of wrongdoing on their part, would constitute a disproportionate response. Similarly, collecting sensitive personal information of all individuals who were present at the scene of crime creates a presumption of criminality which is disproportionate to the objective it aims to achieve.\nD. Procedural safeguards Where there is an appropriate independent institutional mechanism, with in-built procedural safeguards aligned with standards of procedure established by law which are just, fair and reasonable to prevent abuse. At present, there is no independent institutional mechanism which would put in place procedural safeguards in the RFP which will regulate the proposed project. In the absence of any checks and balances, function creep becomes an immediate problem wherein the issue of AFRS being used for functions more than its stated purpose becomes a reality. Use of AFRS without safeguards could result in illegal state-sponsored mass surveillance which would have a chilling effect on fundamental rights such right to freedom of expression, freedom of movement and freedom of association which are guaranteed in the Constitution. Fear of identification and retaliation by the state would deter individuals from exercising their fundamental right to protest which is included in the freedom of speech and expression.\nProject Panoptic IFF has been tracking the RFP for AFRS since last year and has sent two legal notices to the NCRB pertaining to its illegality (Read here and here). Additionally, under our Project Panoptic, we have also been tracking all other instances of facial recognition use in the country that we have come across. Our main aim behind this project is to increase transparency and accountability from the authorities who are implementing these projects.\nImportant Documents  IFF’s Legal Notice to the NCRB on the Revised RFP for the National Automated Facial Recognition System dated July 15, 2020 (link) We might be in the market for a new kind of face mask dated July 18, 2019 (link) We wrote to NCRB and MHA requesting them to halt their ongoing National Automated Facial Recognition System (AFRS) project dated April 22, 2020 (link) Problems with Facial Recognition Technology Operating in a Legal Vacuum dated February 20, 2020 (link) Update on IFF’s #ProjectPanoptic dated July 21, 2020 (link)  ","wordCount":"2238","inLanguage":"en","datePublished":"2020-10-07T04:30:00Z","dateModified":"2020-10-07T04:30:00Z","author":{"@type":"Person","name":"Anushka Jain"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://archive.internetfreedom.in/post/watch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system/"},"publisher":{"@type":"Organization","name":"Internet Freedom Foundation","logo":{"@type":"ImageObject","url":"https://archive.internetfreedom.in/archive/iff-icon-125.png"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<noscript>
<style type=text/css>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://archive.internetfreedom.in accesskey=h title="IFF (Alt + H)">
<img src=/archive/iff-logo-600x250.png alt=logo aria-label=logo height=40>IFF</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://archive.internetfreedom.in/archives title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://archive.internetfreedom.in/about/ title=About>
<span>About</span>
</a>
</li>
<li>
<a href=https://archive.internetfreedom.in/categories/ title=Categories>
<span>Categories</span>
</a>
</li>
<li>
<a href=https://archive.internetfreedom.in/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System
</h1>
<div class=post-meta>October 7, 2020&nbsp;·&nbsp;11 min&nbsp;·&nbsp;Anushka Jain&nbsp;|&nbsp;<a href=https://github.com/InternetFreedomFoundation/archive/tree/main/content/post/watch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system.md rel="noopener noreferrer" target=_blank>Suggest Changes</a>
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<div class=details>Table of Contents</div>
</summary>
<div class=inner><ul>
<li>
<a href=#tldr aria-label=tl;dr>tl;dr</a></li>
<li>
<a href=#history aria-label=History>History</a></li>
<li>
<a href=#what-is-afrs aria-label="What is AFRS?">What is AFRS?</a></li>
<li>
<a href=#what--could-go-wrong aria-label="What  could go wrong?">What could go wrong?</a><ul>
<li>
<a href=#implementation-of-a-faulty-frt-system aria-label="Implementation of a Faulty FRT System">Implementation of a Faulty FRT System</a></li>
<li>
<a href=#implementation-of-an-accurate-frt-system aria-label="Implementation of an Accurate FRT System">Implementation of an Accurate FRT System</a><ul>
<li>
<a href=#a-legality aria-label="A. Legality">A. Legality</a></li>
<li>
<a href=#b-necessity aria-label="B. Necessity">B. Necessity</a></li>
<li>
<a href=#c-proportionality aria-label="C. Proportionality">C. Proportionality</a></li>
<li>
<a href=#d-procedural-safeguards aria-label="D. Procedural safeguards">D. Procedural safeguards</a></li></ul>
</li></ul>
</li>
<li>
<a href=#project-panoptic aria-label="Project Panoptic">Project Panoptic</a></li>
<li>
<a href=#important-documents aria-label="Important Documents">Important Documents</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><figure>
<img loading=lazy src=https://internetfreedom.in/content/images/2020/10/THE-NATIONAL-INTELLIGENCE-GRID--4-.png>
</figure>
<h1 id=tldr>tl;dr<a hidden class=anchor aria-hidden=true href=#tldr>#</a></h1>
<p>The National Automated Facial Recognition System (AFRS) is being developed by the National Crime Records Bureau (NCRB) under the Ministry of Home Affairs. The project aims to develop and use a national database of photographs which is to be used in conjunction with a facial recognition technology system by Central and State security agencies.</p>
<h1 id=history>History<a hidden class=anchor aria-hidden=true href=#history>#</a></h1>
<p>The NCRB first released the <a href=https://drive.google.com/file/d/1rZhDeH9a9E6T7zDTNZoyBdPakwwFFpBU/view>Request for Proposals (RFP)</a> (Document Reference: 02/001).calling for bids for the creation of AFRS on 28 June, 2019 Initially, the deadline for submission of bids was on August 16, 2019 (Read our first post on the subject <a href=https://internetfreedom.in/maskon/>here</a>). However, the deadline was extended multiple times due to reported administrative reasons. Finally, the RFP was <a href=https://drive.google.com/file/d/1qmmdP_Jdk9ceorJa0gAQqFlRjuz6AtOm/view>recalled and cancelled</a>. A <a href=https://drive.google.com/file/d/1KgnURYsFLBqOhLidW28nrbugI--SnKx5/view>new revised version of the RFP</a> [Document Reference: 02/001 (Revised)] was issued on June 22, 2020.</p>
<p>The current deadline for the submission of bids is October 8, 2020.</p>
<p>The estimated budget of the project is INR 308 crore.</p>
<h1 id=what-is-afrs>What is AFRS?<a hidden class=anchor aria-hidden=true href=#what-is-afrs>#</a></h1>
<p>The RFP invites bids for the creation of a National Automated Facial Recognition System (AFRS) to further create a national database of photographs. According to the RFP, this database is purported to be used to swiftly identify criminals by gathering existing data from various other databases like:</p>
<ol>
<li>Passport database under the Ministry of External Affairs,</li>
<li>Crime and Criminal Tracking Network and Systems (CCTNS) by the National Crime Records Bureau(NCRB) under the Ministry of Home Affairs (MHA),</li>
<li>Interoperable Criminal Justice System (ICJS) by the NCRB under the MHA ,</li>
<li>Women and Child Development Ministry&rsquo;s KhoyaPaya Portal,</li>
<li>Automated Fingerprint Identification System (AFIS) by the NCRB under the MHA</li>
<li>Any other image database available with police/other entities.</li>
</ol>
<p>To identify criminals, scene of crime (SOC) images and videos will be matched with the abovementioned databases by using facial recognition technology. <a href=https://www.eff.org/pages/face-recognition>Face recognition systems use computer algorithms to pick out specific, distinctive details about a person’s face. These details, such as distance between the eyes or shape of the chin, are then converted into a mathematical representation and compared to data on other faces collected in a face recognition database. The data about a particular face is often called a face template and is distinct from a photograph because it’s designed to only include certain details that can be used to distinguish one face from another.</a></p>
<h1 id=what--could-go-wrong>What could go wrong?<a hidden class=anchor aria-hidden=true href=#what--could-go-wrong>#</a></h1>
<p>Identification happens when FRT is used to identify an individual from a pool of many people. This kind of 1: many FRT based identification is typically used for security and surveillance purposes. Verification, on the other hand, occurs when an image is compared to another image from an existing database in order to verify that the individual is who he/she claims to be, i.e., authentication of identity on a 1:1 basis.</p>
<h2 id=implementation-of-a-faulty-frt-system>Implementation of a Faulty FRT System<a hidden class=anchor aria-hidden=true href=#implementation-of-a-faulty-frt-system>#</a></h2>
<p>Claims relating to accuracy of FRT systems are routinely exaggerated and the real numbers leave much to be desired. The implementation of such faulty FRT systems would lead to high rates of false positives and false negatives in this recognition process.</p>
<ol>
<li>A false positive occurs when FRT gives an incorrect positive result wherein the system misidentifies an individual as someone he/she is not. This may lead to discrimination and strengthening of existing biases. For instance, <a href=https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28>ACLU</a> found that Amazon’s facial recognition software “Rekognition” incorrectly matched 28 members of the US Congress with people who had been arrested for committing a crime. Of those members who were incorrectly matched, 40% were people of color which is a disproportionate number since people of color make up only 20% of the US Congress.</li>
<li>A false negative occurs when the FRT gives an incorrect negative result wherein the system is unable to recognize an individual or authenticate his/her identity. This may lead to arbitrary exclusion of an individual from government schemes and benefits. Failure of biometric based authentication under Aadhaar has led to many people being excluded from receiving essential government services and even led to starvation deaths. Such problems will be further aggravated by an inaccurate FRT system.</li>
</ol>
<p>The AFRS is being developed and deployed by the government without any technical standards in place which may lead to faulty systems being implemented. Once in place, it would be very difficult for it to be reconciled with future technical standards and damage like discrimination and exclusion would be impossible to undo. In the revised RFP, there is no mention of the international standards which were included in the original RFP which had to be complied with as a technical requirement. The reason behind the exclusion of these standards is unclear and raises the question of why necessary standards of technical requirements are being diluted.</p>
<h2 id=implementation-of-an-accurate-frt-system>Implementation of an Accurate FRT System<a hidden class=anchor aria-hidden=true href=#implementation-of-an-accurate-frt-system>#</a></h2>
<p>While there have been <a href="https://swr.indianrailways.gov.in/view_detail.jsp?lang=0&dcd=3370&id=0,4,268">claims</a> of a fully accurate FRT system, none of these claims have been corroborated by independent review and audit. The National Institute of Standards and Technology (NIST) has extensively tested FRT systems for <a href=https://www.nist.gov/system/files/documents/2019/11/20/frvt_report_2019_11_19_0.pdf>1:1 verification</a> and <a href=https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8271.pdf>1:many identification</a> and how accuracy of these systems <a href=https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf>vary across demographic groups</a>. These independent studies have concluded that currently, no FRT system has 100% accuracy.</p>
<p>An accurate FRT system would hypothetically have a 100% success rate in 1:1 verification and/or 1:many identification. However, it will come with its own ominous connotations, the most problematic of which may be state led mass surveillance and difficulty for outside actors to counter-challenge government decisions.</p>
<p>Probe images for FRT systems are often collected by the police through CCTV cameras installed in public spaces. Individuals in a CCTV surveilled area may be aware that they are under surveillance but the assumption is that this surveillance is temporary. Use of CCTV in conjunction with FRT would mean their images will be stored for a longer period of time, if not permanently. This data will also be used to extract particular data points such as the facial features and other biometrics which the individual has not consented to sharing when entering a CCTV surveilled zone and these data points can be used to track future movements of the person. Therefore, integration of FRT with a network of CCTV cameras would make real time surveillance extremely easy.</p>
<p>One of the most important changes which have been made in the revised RFP is that it now states that the project “does not involve the installation of CCTV camera nor will it connect to any existing CCTV camera anywhere”. This is a departure from the original RFP wherein CCTV integration had been included as a functional requirement.</p>
<p>However in the revised RFP, a new data source &ldquo;Scene of Crime images/videos&rdquo; has been introduced for input into the AFRS database. This inclusion is at odds with the previous assertion made in the RFP - that integration of CCTVs will not take place. Deletion of CCTV camera footage as a data source leaves a gap in the functional architecture of AFRS and the RFP fails to satisfactorily account for its replacement. The RFP also fails to mention how the data and subsequent analysis/ information which is obtained through AFRS will be presented and utilized in a court of law, i.e., the nature of the evidence obtained from AFRS and its admissibility as pertaining to its reliability in courts.</p>
<p>Deployment of AFRS without adequate legal safeguards is deeply troubling. Specific laws with regard to FRT and personal data protection do not currently exist in India. While a flawed Personal Data Protection Bill has been introduced in the Parliament (read more <a href=https://internetfreedom.in/its-the-final-countdown-kinda-saveourprivacy/>here</a>), there is uncertainty about when it will be enacted and implemented and how effective it will be in protecting the personal data of individuals. Under the current version of the Bill, wide exceptions have been provided to the Government for surveillance related activities. A strong data protection legislation is needed to hold these FRT systems accountable in terms of collection, storage and usage of data including sharing of data across government agencies and with third parties.</p>
<p>The implementation of an accurate FRT system would also violate fundamental rights by facilitating mass surveillance. For instance, there will be a chilling effect on the right to freedom of speech and expression because people will be wary of being prosecuted in case they express anti-government sentiments. Further, the right to freedom of movement would be hampered as mass surveillance would allow the government to track the movements of individuals in real time across the country. Finally, the right to privacy will be violated as sensitive personal data which is collected by these FRT systems will be used by the Government without the informed consent of the individual. This would also hamper the individual from exercising the liberty to share their information in some contexts and remain anonymous in others according to their individual choice.</p>
<p>As per the Hon’ble Supreme Court&rsquo;s decision in <em>Justice K.S. Puttaswamy vs Union of India</em> (2017 10 SCC 1) any justifiable intrusion by the State into people’s right to privacy protected under Article 21 of the Constitution must conform to certain thresholds. These thresholds are:</p>
<h3 id=a-legality>A. Legality<a hidden class=anchor aria-hidden=true href=#a-legality>#</a></h3>
<p>Where the intrusion must take place a defined regime of law i.e. there must be an anchoring legislation, with a clear set of provisions. As pointed out in our previous legal notice as well, there is no anchoring legislation which allows for and regulates the use of AFRS. In the absence of such a framework and safeguards, the first requirement for lawful restriction on the right to privacy is not met.</p>
<h3 id=b-necessity>B. Necessity<a hidden class=anchor aria-hidden=true href=#b-necessity>#</a></h3>
<p>Which justifies that the restriction to people’s privacy (in this case data collection and sharing) is needed in a democratic society to fulfill a legitimate state aim. In the RFP, it is stated that the need for AFRS arises because it will enable automatic identification and verification through criminal databases which would help investigation of crime and tracking and detection of criminals.</p>
<p>This characterisation is based on a faulty assumption that facial recognition technology is accurate and would provide speedy and correct results. However, ongoing research in the field has shown that facial recognition technology which is completely accurate has not been developed yet. Use of such inaccurate technology, especially for criminal prosecution, could thus result in a false positive, i.e., misidentification of an innocent individual as a suspect in a crime. Thus, AFRS fails to meet the requirement of necessity as laid down by the Supreme Court in the Puttaswamy judgment.</p>
<h3 id=c-proportionality>C. Proportionality<a hidden class=anchor aria-hidden=true href=#c-proportionality>#</a></h3>
<p>Where the Government must show among other things that the measure being undertaken has a rational nexus with the objective. The AFRS contemplates collecting sensitive personal information, intimate information of all individuals in the absence of any reasonable suspicion by collecting images and videos from a scene of crime. This could cast a presumption of criminality on a broad set of people. In the Supreme Court’s decision in K.S. Puttaswamy v. Union of India (2019) 1 SCC 1 or the Aadhaar judgment , the Hon’ble Supreme Court held that:</p>
<blockquote>
<p>“[u]nder the garb of prevention of money laundering or black money, there cannot be such a sweeping provision which targets every resident of the country as a suspicious person”</p>
</blockquote>
<p>While this statement was made in the context of rejecting the mandatory linkage of Aadhaar with bank accounts to counter money laundering, it clearly shows that imposition of such a restriction on the entire population, without any evidence of wrongdoing on their part, would constitute a disproportionate response. Similarly, collecting sensitive personal information of all individuals who were present at the scene of crime creates a presumption of criminality which is disproportionate to the objective it aims to achieve.</p>
<h3 id=d-procedural-safeguards>D. Procedural safeguards<a hidden class=anchor aria-hidden=true href=#d-procedural-safeguards>#</a></h3>
<p>Where there is an appropriate independent institutional mechanism, with in-built procedural safeguards aligned with standards of procedure established by law which are just, fair and reasonable to prevent abuse. At present, there is no independent institutional mechanism which would put in place procedural safeguards in the RFP which will regulate the proposed project. In the absence of any checks and balances, function creep becomes an immediate problem wherein the issue of AFRS being used for functions more than its stated purpose becomes a reality. Use of AFRS without safeguards could result in illegal state-sponsored mass surveillance which would have a chilling effect on fundamental rights such right to freedom of expression, freedom of movement and freedom of association which are guaranteed in the Constitution. Fear of identification and retaliation by the state would deter individuals from exercising their fundamental right to protest which is included in the freedom of speech and expression.</p>
<h1 id=project-panoptic>Project Panoptic<a hidden class=anchor aria-hidden=true href=#project-panoptic>#</a></h1>
<p>IFF has been tracking the RFP for AFRS since last year and has sent two legal notices to the NCRB pertaining to its illegality (Read <a href=https://internetfreedom.in/iffs-legal-notice-to-the-ncrb-on-the-revised-rfp-for-the-national-automated-facial-recognition-system/>here</a> and <a href=https://internetfreedom.in/maskon/>here</a>). Additionally, under our Project Panoptic, we have also been tracking all other instances of facial recognition use in the country that we have come across. Our main aim behind this project is to increase transparency and accountability from the authorities who are implementing these projects.</p>
<h1 id=important-documents>Important Documents<a hidden class=anchor aria-hidden=true href=#important-documents>#</a></h1>
<ol>
<li>IFF&rsquo;s Legal Notice to the NCRB on the Revised RFP for the National Automated Facial Recognition System dated July 15, 2020 (<a href=https://internetfreedom.in/iffs-legal-notice-to-the-ncrb-on-the-revised-rfp-for-the-national-automated-facial-recognition-system/>link</a>)</li>
<li>We might be in the market for a new kind of face mask dated July 18, 2019 (<a href=https://internetfreedom.in/maskon/>link</a>)</li>
<li>We wrote to NCRB and MHA requesting them to halt their ongoing National Automated Facial Recognition System (AFRS) project dated April 22, 2020 (<a href=https://internetfreedom.in/we-wrote-to-ncrb-and-mha-requesting-them-to-halt-their-ongoing-national-automated-facial-recognition-system-afrs-project/>link</a>)</li>
<li>Problems with Facial Recognition Technology Operating in a Legal Vacuum dated February 20, 2020 (<a href=https://internetfreedom.in/problems-with-facial-recognition-systems-operating-in-a-legal-vacuum/>link</a>)</li>
<li>Update on IFF&rsquo;s #ProjectPanoptic dated July 21, 2020 (<a href=https://internetfreedom.in/update-on-iffs-projectpanoptic/>link</a>)</li>
</ol>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://archive.internetfreedom.in/tags/facial-recognition/>facial recognition</a></li>
<li><a href=https://archive.internetfreedom.in/tags/project-panoptic/>Project Panoptic</a></li>
<li><a href=https://archive.internetfreedom.in/tags/watchthewatchmen/>WatchtheWatchmen</a></li>
<li><a href=https://archive.internetfreedom.in/tags/surveillance/>Surveillance</a></li>
<li><a href=https://archive.internetfreedom.in/tags/saveourprivacy/>SaveOurPrivacy</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://archive.internetfreedom.in/post/aadhaar-good-governance-rules/>
<span class=title>« Prev Page</span>
<br>
<span>While India copes with COVID-19, Aadhaar continues its function creep #SaveOurPrivacy</span>
</a>
<a class=next href=https://archive.internetfreedom.in/post/read-our-comments-on-the-dots-paper-to-develop-an-indian-artificial-intelligence-stack-2/>
<span class=title>Next Page »</span>
<br>
<span>Read our comments on the DoT's Paper to develop an Indian Artificial Intelligence Stack</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System on twitter" href="https://twitter.com/intent/tweet/?text=Watch%20the%20Watchmen%20Series%20Part%204%20%3a%20The%20National%20Automated%20Facial%20Recognition%20System&url=https%3a%2f%2farchive.internetfreedom.in%2fpost%2fwatch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system%2f&hashtags=facialrecognition%2cProjectPanoptic%2cWatchtheWatchmen%2cSurveillance%2cSaveOurPrivacy"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2farchive.internetfreedom.in%2fpost%2fwatch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system%2f&title=Watch%20the%20Watchmen%20Series%20Part%204%20%3a%20The%20National%20Automated%20Facial%20Recognition%20System&summary=Watch%20the%20Watchmen%20Series%20Part%204%20%3a%20The%20National%20Automated%20Facial%20Recognition%20System&source=https%3a%2f%2farchive.internetfreedom.in%2fpost%2fwatch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System on reddit" href="https://reddit.com/submit?url=https%3a%2f%2farchive.internetfreedom.in%2fpost%2fwatch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system%2f&title=Watch%20the%20Watchmen%20Series%20Part%204%20%3a%20The%20National%20Automated%20Facial%20Recognition%20System"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2farchive.internetfreedom.in%2fpost%2fwatch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System on whatsapp" href="https://api.whatsapp.com/send?text=Watch%20the%20Watchmen%20Series%20Part%204%20%3a%20The%20National%20Automated%20Facial%20Recognition%20System%20-%20https%3a%2f%2farchive.internetfreedom.in%2fpost%2fwatch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Watch the Watchmen Series Part 4 : The National Automated Facial Recognition System on telegram" href="https://telegram.me/share/url?text=Watch%20the%20Watchmen%20Series%20Part%204%20%3a%20The%20National%20Automated%20Facial%20Recognition%20System&url=https%3a%2f%2farchive.internetfreedom.in%2fpost%2fwatch-the-watchmen-series-part-4-the-national-automated-facial-recognition-system%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://archive.internetfreedom.in>Internet Freedom Foundation</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)">
<button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</button>
</a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>