+++
author = 'Anushka Jain'
categories = ['Project Panoptic', 'facial recognition']
date = 2021-05-13T07:16:45Z
description = ''
draft = false
image = 'https://internetfreedom.in/content/images/2021/05/1-5.png'
slug = 'facial-recognition-laws-in-europe-projectpanoptic'
summary = 'In the second part of our series on FRT regulation around the world, we will take a look at what are the existing laws regulating FRT in Europe and where regulation is headed.'
tags = ['Project Panoptic', 'facial recognition']
title = 'Facial Recognition Laws in Europe #ProjectPanoptic'

+++


{{< gallery >}}
{{< galleryImg  src="https://internetfreedom.in/content/images/2021/05/1-4.png" width="4800" height="2700" >}}{{< /gallery >}}

>>>> <form><script src="https://checkout.razorpay.com/v1/payment-button.js" data-payment_button_id="pl_HLkgeWGQLMuddp" async> </script> </form>

### tl;dr

In the [first part](https://internetfreedom.in/facial-recognition-laws-in-the-united-states-projectpanoptic/) of this series, we looked at how the United States has responded to the proliferation of harmful facial recognition technology (FRT) in their country. In this post, we will be looking at the diametrically different approach to FRT that has been taken in Europe. While the US is responding post-facto to the use of FRT, Europe is grappling with the conundrum of how use of FRT corresponds to its existing laws.

### FRT regulation in Europe

Europe consists of around fifty countries, of which 27 countries are a part of the European Union. The table below illustrates the respective country’s stance on FRT. The stance of countries which have not been included in the table could not be verified through a valid source.

| Country        | Stance on FRT                      |
|----------------|------------------------------------|
| Armenia        | [In use](https://carnegieendowment.org/files/WP-Feldstein-AISurveillance_final.pdf)                             |
| Austria        | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Belarus        | [In use](https://www.biometricupdate.com/201903/belarus-to-begin-issuing-biometric-passports-next-january)                             |
| Belgium        | [Ban](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                                |
| Bulgaria       | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Croatia        | [Considering use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                    |
| Cyprus         | [In use](https://www.biometricupdate.com/201807/cyprus-airports-add-biometric-kiosks-for-entry-and-exit-processing)                             |
| Czech Republic | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Denmark        | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| England        | [In use](https://bigbrotherwatch.org.uk/campaigns/stop-facial-recognition/#facial-recognition-map)                             |
| Estonia        | [Approved for use (not implemented)](https://algorithmwatch.org/en/story/face-recognition-police-europe/) |
| Finland        | [Approved for use (not implemented)](https://yle.fi/uutiset/osasto/news/finnish_police_customs_now_able_to_use_facial_id_tech_but_infrastructure_not_in_place/10818526) |
| France         | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Germany        | [In use](https://www.politico.eu/article/berlin-big-brother-state-surveillance-facial-recognition-technology/)                             |
| Greece         | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Hungary        | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Iceland        | [In use](https://findbiometrics.com/biometric-screening-iceland-airport-403203/)                             |
| Ireland        | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Italy          | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Luxembourg     | [Ban](https://delano.lu/d/detail/news/no-facial-recognition-lux-cctv/208048)                                |
| Malta          | [In use](https://carnegieendowment.org/files/WP-Feldstein-AISurveillance_final.pdf)                             |
| Moldova        | [In use](https://privacyinternational.org/examples/3629/moldova-transnistria-uses-facial-recognition-identify-quarantine-violators)                             |
| Netherlands    | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Norway         | [In use](https://www.biometricupdate.com/201807/oslo-airport-deploys-idemia-facial-recognition-technology)                             |
| Poland         | [Approved for use (not implemented)](https://algorithmwatch.org/en/story/face-recognition-police-europe/) |
| Portugal       | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Romania        | [Approved for use (not implemented)](https://algorithmwatch.org/en/story/face-recognition-police-europe/) |
| Russia         | [In use](https://www.amnesty.org/en/latest/news/2021/04/russia-police-target-peaceful-protesters-identified-using-facial-recognition-technology/)                             |
| Scotland       | [Considering use](https://www.bbc.com/news/uk-scotland-51449166)                    |
| Serbia         | [In use](https://www.eff.org/deeplinks/2019/12/activists-worldwide-face-against-face-recognition-2019-year-review)                             |
| Slovakia       | [Approved for use (not implemented)](https://algorithmwatch.org/en/story/face-recognition-police-europe/) |
| Slovenia       | [In use](https://algorithmwatch.org/en/story/face-recognition-police-europe/)                             |
| Spain          | [In use](https://algorithmwatch.org/en/spain-mendez-alvaro-face-recognition/)                             |
| Sweden         | [Approved for use (not implemented)](https://algorithmwatch.org/en/story/face-recognition-police-europe/) |
| Switzerland    | [In use](https://www.swissinfo.ch/eng/biometric-id_zurich-airport-to-pilot-face-recognition-system/43504538)                             |



### Existing and proposed regulations for FRT in Europe

Unlike the US and India, the member countries of the EU have a first line of defence against FRT in the form of the GDPR. The GDPR, under [Art. 5](https://gdpr-info.eu/art-5-gdpr/), puts into place certain principles based on which personal data can be processed. These principles are ‘lawfulness, fairness and transparency’, ‘purpose limitation’, ‘data minimisation’, ‘accuracy’, ‘storage limitation’, ‘integrity and confidentiality’ and ‘accountability’. Further, under [Art. 9](https://gdpr-info.eu/art-9-gdpr/), the GDPR prohibits the processing of personal data revealing biometric data for the purpose of uniquely identifying a natural person. 

However according to [Daniel Leufer](https://twitter.com/djleufer), Access Now’s Europe Policy Analyst, “(t)here are quite a few exceptions to Art 9, such as (e) "processing relates to personal data which are manifestly made public by the data subject;" and (g) "processing is necessary for reasons of substantial public interest, on the basis of Union or Member State law which shall be proportionate to the aim pursued, respect the essence of the right to data protection and provide for suitable and specific measures to safeguard the fundamental rights and the interests of the data subject", which allow for exemptions and/or abuse.” It is probable that the use of FRT in multiple countries across Europe, as seen in the table above, is being done on the basis of these exceptions. As a result, Access Now, EDRi, and other civil society organisations across Europe have come together to launch the [Reclaim Your Face](https://reclaimyourface.eu/) campaign to stop mass surveillance through facial recognition.

The Law Enforcement Directive (LED) is a legislation that runs parallel to the GDPR in the EU and relates specifically to the processing of personal data by data controllers for ‘law enforcement purposes’, which falls outside of the scope of the GDPR. [Art.10](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016L0680&rid=2#d1e1365-89-1) of the LED states that, “Processing of special categories of personal data: Processing of personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership, and the processing of genetic data, biometric data for the purpose of uniquely identifying a natural person, data concerning health or data concerning a natural person's sex life or sexual orientation **shall be allowed** [emphasis added] only where strictly necessary, subject to appropriate safeguards for the rights and freedoms of the data subject, and only:

1. where authorised by Union or Member State law;
2. to protect the vital interests of the data subject or of another natural person; or
3. where such processing relates to data which are manifestly made public by the data subject.”

At present there is an active proposal on harmonised rules on artificial intelligence (Artificial Intelligence Act) in the European Commission. Under Art. 5(1)(d) of the [proposal](https://ec.europa.eu/newsroom/dae/items/709090), use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement is prohibited, however, the wide exemptions attached to this provision [weaken](https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/) it severely by acting as loopholes. The article also does not apply to other authorities or private companies and relates only to “real-time” uses thereby creating another loophole. In response to the proposal, the European Data Protection Supervisor (EDPS), EU’s privacy watchdog, stated in a [press release](https://edps.europa.eu/press-publications/press-news/press-releases/2021/artificial-intelligence-act-welcomed-initiative_en) that “ban on remote biometric identification in public space is necessary”.



### Specific developments in the United Kingdom

Since the UK has exited the EU, the GDPR and the LED are not applicable to it (after the transition period) and the new AI Act proposal will also not apply to it. However, the UK has the Data Protection Act, 2018 which regulates how personal information is used by organisations, businesses or the government. The Data Protection Act, 2018 is the UK’s implementation of the GDPR and thus, in practice, applies the same principles as the GDPR with regard to processing of personal data in addition to having the similar shortcomings.

In addition to legislation, one of the leading legal precedent in this area is the case of _Ed Bridges v. South Wales Police_: Landmark case on FRT decided by the Court Of Appeal (Civil Division). After the London High Court, in September, 2019 ruled that use of FRT on Ed Bridges was not unlawful, the Court of Appeal in August, 2020 ruled that “[use of automatic facial recognition (AFR) technology by South Wales Police is unlawful](https://www.bbc.com/news/uk-wales-53734716#:~:text=The%20use%20of%20automatic%20facial,Court%20of%20Appeal%20has%20ruled.&text=But%20the%20court%20also%20found,the%20impact%20on%20Mr%20Bridges.)”. This favourable outcome has been hailed by many as a big step in the fight against FRT as it is touted to be the [world's first legal challenge to police use of facial recognition technology](https://www.libertyhumanrights.org.uk/issue/liberty-wins-ground-breaking-victory-against-facial-recognition-tech/).

We hope this analysis helps guide researchers, advocates and groups in India on the path forward for crafting a legal framework for FRT regulation in India that may include banning its deployment for specific purposes.

### FRT regulation around the world

Under IFF’s Project Panoptic, we have called for a ban on government entities, police and other security/intelligence agencies using FRT. In this series, we will be taking a look at how our stance measures up against developments on FRT regulations around the world. For the third post in this series we will be focusing on China, so stay in touch with us and keep following Project Panoptic.

<iframe src="https://drive.google.com/file/d/1lgOSBidAGpfIaxmbudzAW9B803j4Ihh_/preview" width="580" height="480"></iframe>

### Important Documents

1. Project Panoptic’s petition calling for a ban on government use of FRT ([link](https://panoptic.in/petition))
2. Facial Recognition Laws in the United States dated May 3, 2021 ([link](https://internetfreedom.in/facial-recognition-laws-in-the-united-states-projectpanoptic/))

> > > <form><script src="https://cdn.razorpay.com/static/widget/subscription-button.js" data-subscription_button_id="pl_HLk5qU1K35hmPH" data-button_theme="brand-color" async> </script> </form>













