+++
author = 'Anushka Jain'
categories = ['Project Panoptic', 'facial recognition', 'Surveillance']
date = 2021-11-11T06:38:05Z
description = ''
draft = false
slug = 'project-panoptic-has-partnered-with-amnesty-international-article-19-to-launch-banthescan-in-india'
summary = "IFF's Project Panoptic has partnered with Amnesty International and Article 19 to launch the #BanTheScan campaign against the rampant proliferation of facial recognition use in Hyderabad. "
tags = ['Project Panoptic', 'facial recognition', 'Surveillance']
title = 'Project Panoptic has partnered with Amnesty International & Article 19 to launch #BanTheScan in India'

+++


{{< gallery >}}
{{< galleryImg  src="https://internetfreedom.in/content/images/2021/11/BTS-IFF-header.jpeg" width="1600" height="900" >}}{{< /gallery >}}

On November 10, 2021, Project Panoptic, partnering with Amnesty International and Article 19 launched the India edition of their global #BanTheScan campaign for [Hyderabad](https://banthescan.amnesty.org/hyderabad/). The city - one of the most surveilled cities in the world - has begun construction of an ominous ‘Command and Control Centre’ (CCC), intended to connect the state's vast facial recognition-capable CCTV infrastructure in real time. In addition, Project Panoptic has found that Telangana state has the [highest number of facial recognition](https://panoptic.in/telangana) technology (FRT) projects in India.

“Hyderabad is on the brink of becoming a total surveillance city. It is almost impossible to walk down the street without risking exposure to facial recognition” said Matt Mahmoudi, Amnesty International’s AI and Big Data researcher. “In addition to CCTV, we are concerned that law enforcement’s practice of using tablets to stop, search and photograph civilians without charge could be used for facial recognition.”

“Facial recognition technology can track who you are, where you go, what you do, and who you know. It threatens human rights including the right to privacy, and puts some of the most vulnerable in society at risk. The construction of the CCC has chilling consequences for the right to freedom of expression and assembly.” said Quinn McKew, Executive Director at ARTICLE 19.

“There is currently no legislation in place to protect the privacy of citizens – facial recognition is a harmful and invasive technology and it is imperative that Indian authorities immediately stop the use of this dangerous technology” said Anushka Jain, Internet Freedom Foundation’s Associate Counsel for Surveillance & Transparency.

Authorities in India have a lengthy record of using facial recognition technology in contexts where human rights are at stake, with recent examples including enforcing [COVID-19 lockdown measures](https://internetfreedom.in/hyderabad-police-force-people-to-remove-their-masks-before-photographing-them-we-sent-a-legal-notice-saveourprivacy/), [identifying voters in municipal elections](https://panoptic.in/case-study/illegal-use-of-facial-recognition-for-voter-verification-in-telangana), and [policing protests](https://panoptic.in/case-study/the-delhi-police-must-stop-its-facial-recognition-system). The rights of Muslims, Dalits, Adivasis, Transgender communities, and historically disadvantaged sections of society, are particularly at risk by mass surveillance.

{{< gallery caption=""How Your Face is Used to Track You" by Tanu Sathaye" >}}
{{< galleryImg  src="https://internetfreedom.in/content/images/2021/11/New-India-Comic--white-background--3.png" width="1910" height="1169" >}}{{< /gallery >}}

The research in India marks the latest phase of Amnesty International’s Ban The Scan campaign, following research into [surveillance in New York City](https://www.amnesty.org/en/latest/press-release/2021/01/ban-dangerous-facial-recognition-technology-that-amplifies-racist-policing/) published earlier this year. The Hyderabad research is in partnership with the [Internet Freedom Foundation](https://internetfreedom.in/)’s [Project Panoptic](https://panoptic.in/) and [Article 19](https://www.article19.org/).

Project Panoptic is calling for a [complete ban](https://panoptic.in/petition) on the use of this technology by the government entities, police and other security/intelligence agencies and Amnesty International is calling for a total ban on the state and private sector use, development, production, sales, and export of facial recognition technology for mass surveillance purposes.



### Automated harassment in Hyderabad

In recent years, Telangana state has been a test site for increased usage of dangerous facial recognition technologies (FRT) against civilians. Situated in Hyderabad's Banjara Hills, the CCC will reportedly support the processing of data from up to 600,000 cameras at once, with the possibility to increase this scope much further across the region. These cameras can be used in combination with Hyderabad Police’s existing facial recognition software to track individuals.

Amnesty International, IFF and Article 19 mapped the locations of visible outdoor CCTV infrastructure in two sampled neighbourhoods in Hyderabad – Kala Pathar and Kishan Bagh, with the help of local volunteers. Based on geospatial analysis, it was estimated that in these neighbourhoods at least 530,864 and 513,683 square meters, respectively, was covered by CCTV cameras – a remarkable total of 53.7% and 62.7% of the entire area.

Amnesty International discovered footage of dozens of incidents shared on social media from November 2019 to July 2021 showing Hyderabad Police asking civilians to remove their masks and photographing them in the streets, refusing to explain why. Other cases have shown police randomly demanding both facial and fingerprint reads from civilians.

Under India’s Identification of Prisoners Act of 1920, it is not permitted to take photographs of persons by police, unless arrested or convicted of a crime, and neither is the sharing of such photographs with other law enforcement agencies.



### Control of facial recognition technology in India

Amnesty International contacted five companies (IDEMIA, NEC India, Staqu, Vision-Box and INNEFU Labs) for more information regarding their facial recognition related activities in India, and to request any human rights policies they may have.

Of the companies contacted, only INNEFU responded to the July 2021 letter, stating “the user agency is not under any obligation to adhere to any terms and conditions of the vendor”, without granting further responses to any of the 14 questions posed by Amnesty International. In another letter responding to Amnesty International about a previous investigation, INNEFU admitted that it did not have a “stated human rights policy”, but that it was “follow[ing] Indian laws and guidelines”.

Under the UN Guiding Principles on Business and Human Rights, all companies must have a human rights policy in place, and take steps to identify, prevent, mitigate and account for the risks to human rights posed by their operations and any risks they are linked to through their business relationships, products or services.

Facial recognition technology inherently poses a high risk to human rights, and these five vendors have failed to demonstrate they are adequately addressing and mitigating the risks of providing this technology to government agencies.

### For more information or to arrange an interview, please contact:

[laurie.hanna@amnesty.org](mailto:laurie.hanna@amnesty.org)

[natashaschmidt@article19.org](mailto:natashaschmidt@article19.org)

[media@internetfreedom.in](mailto:media@internetfreedom.in)  

